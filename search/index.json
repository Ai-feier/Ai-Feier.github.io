[{"content":"写时复制 dockerfile 一条指令对应一层, 最多 127 层\n从 busybox 入手理解 docker 镜像层的写时复制\ndockerfile:\n1 2 3 4 5 6 7 8 9 FROM busybox RUN mkdir -p /tmp/foo # 新建一个 100M 的文件 RUN dd if=/dev/zero of=/tmp/foo/bar bs=1M count=100 # 删除文件 RUN rm /tmp/foo/bar 一条指令对应 1 层: 4 层\n1 2 3 4 $ docker build -t busybox:copy-on-write -f dockerfile1 . $ docker images | grep busybox busybox copy-on-write 1f30f7a048eb About a minute ago 106MB busybox latest beae173ccac6 2 years ago 1.24MB 看得出来就算镜像删除的文件, 下层创建的不会消失, 删除指令创建的层只会叠加上去\n使用 docker inspect 查看具体的层信息\nbusybox:latest\n1 2 3 4 5 6 7 8 9 10 docker inspect busybox:latest ...... \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:82ae998286b2bba64ce571578647adcabef93d53867748d6046cc844ff193a83\u0026#34; ] }, ...... busybox:copy-on-write\n1 2 3 4 5 6 7 8 9 10 11 12 13 docker inspect busybox:copy-on-write ...... \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:82ae998286b2bba64ce571578647adcabef93d53867748d6046cc844ff193a83\u0026#34;, \u0026#34;sha256:f70c1ce3ef10664a7aacf002afd20aa16f56bf98a83729b640c97363b10d329c\u0026#34;, \u0026#34;sha256:3c38ae07f686f954897d06c4c56e65e17d1be5843f2c02e8f2d6734b4978dd83\u0026#34;, \u0026#34;sha256:69d9b35636c7fa1f62c4bfe15f3c65f247553b122fe38af17dc34666f8cb2314\u0026#34; ] }, ...... 可以看到 busybox:copy-on-write 明显增加了层数\n制作精简镜像方法: 串联 Dockerfile 指令 选用更小的镜像 压缩镜像 案例: 二进制部署 redis\n多条命令构建 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 FROM ubuntu:trusty ENV VER 7.2.3 # 安装依赖 RUN apt update RUN apt install wget make gcc -y # 获取源码包 RUN wget https://download.redis.io/releases/redis-$VER.tar.gz RUN tar zxvf redis-$VER.tar.gz WORKDIR redis-$VER # 编译源码包 RUN make RUN mkdir /usr/local/redis RUN make install PREFIX=/usr/local/redis RUN apt-get clean \u0026amp;\u0026amp; apt-get remove -y wget gcc make # 启动 redis CMD [\u0026#34;/usr/local/redis/redis-server\u0026#34;, \u0026#34;/usr/local/redis/redis.conf\u0026#34;] 构造镜像 1 docker build -t redis:many-lines-ubuntu -f dockerfile2 . ROOTFS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...... \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:f2fa9f4cf8fd0a521d40e34492b522cee3f35004047e617c75fadeb8bfd1e6b7\u0026#34;, \u0026#34;sha256:30d3c4334a2379748937816c01f5c972a8291a5ccc958d6b33d735457a16196e\u0026#34;, \u0026#34;sha256:83109fa660b2ed9307948505abd3c1f24c27c64009691067edb765bd3714b98d\u0026#34;, \u0026#34;sha256:87c240db20b96e01aa53111dbf1a71b54095e95f2bb32076a7aee2de148aaaf1\u0026#34;, \u0026#34;sha256:c45a2d4a77a5eb88bd2bfaaa691468eade520c8da9b3d39d30813e9882ff7b0b\u0026#34;, \u0026#34;sha256:65faa09184aa345eeace30548ad9a337e4582f9b23d8a0871ad8a5be08fe6c09\u0026#34;, \u0026#34;sha256:af54af5d0e940764f3cd2b78d5ab121b2dba5eb1f527e81f8c70c3deeddf15b9\u0026#34;, \u0026#34;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef\u0026#34;, \u0026#34;sha256:1819a309db341aed9bc39e040a3695151d2b33c9d1d267069d6f3918f3871a1d\u0026#34;, \u0026#34;sha256:e54f0072570654b50dd413197f5d921da283c90689d79336ed0c313112d3a591\u0026#34;, \u0026#34;sha256:b6499beec6f2099e86807b4fee915170820834dfafae3ca324309db26e5660fb\u0026#34;, \u0026#34;sha256:14a95f408690a544c45387595381902f921eb0356a53f8a73495198dc113b8a1\u0026#34;, \u0026#34;sha256:a545e5b1525c37272eb70af26d8baab872f592c5f71ba934353a7104f0680e21\u0026#34; ] }, ...... 由于我们写了写多条 RUN 指令, 所以镜像 ROOTFS 极速增长\n一条命令构建 ubuntu 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FROM ubuntu:trusty ENV VER 7.2.3 RUN apt update \u0026amp;\u0026amp; \\ apt install wget make gcc -y \u0026amp;\u0026amp; \\ wget https://download.redis.io/releases/redis-$VER.tar.gz \u0026amp;\u0026amp; \\ tar zxvf redis-$VER.tar.gz \u0026amp;\u0026amp; cd redis-$VER \u0026amp;\u0026amp; \\ make \u0026amp;\u0026amp; mkdir /usr/local/redis \u0026amp;\u0026amp; \\ make install PREFIX=/usr/local/redis \u0026amp;\u0026amp; \\ mkdir -p /usr/local/redis/{conf,bin} \u0026amp;\u0026amp; \\ cp redis.conf /usr/local/redis/conf \u0026amp;\u0026amp; \\ apt-get clean \u0026amp;\u0026amp; apt-get remove -y wget gcc make # 启动 redis CMD [\u0026#34;/usr/local/redis/bin/redis-server\u0026#34;, \u0026#34;/usr/local/redis/conf\u0026#34;] 构造镜像 1 docker build -t redis:one-line-ubuntu -f dockerfile2 . ROOTFS 1 2 3 4 5 6 7 8 9 10 11 12 13 docker inspect redis:one-line-ubuntu ...... \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:f2fa9f4cf8fd0a521d40e34492b522cee3f35004047e617c75fadeb8bfd1e6b7\u0026#34;, \u0026#34;sha256:30d3c4334a2379748937816c01f5c972a8291a5ccc958d6b33d735457a16196e\u0026#34;, \u0026#34;sha256:83109fa660b2ed9307948505abd3c1f24c27c64009691067edb765bd3714b98d\u0026#34;, \u0026#34;sha256:72caaf8c025e80d97674e4d68ac4628b8dabab70dc9b73ef817c51b694c45daa\u0026#34; ] }, ...... 可以看出指令数减少, ROOTFS 层数也明显减少\n更改基础镜像为 debian 巨坑: debian 与 alpine 的镜像在切换国内时问题非常多, 建议直接使用原始镜像的软件源(确保能够访问外网)\n问题概览:\ndebian 低版本切换阿里源时, 不支持 https: 需要将 http 软连接为 https 显示 gpg key 错误时: wget http://http.us.debian.org/debian/pool/main/d/debian-archive-keyring/debian-archive-keyring_2023.4_all.deb \u0026amp;\u0026amp; dpkg -i debian-archive-keyring_2023.4_all.deb alpline 与 debian 安装的 gcc 可能会出现版本问题, 需要你更换 gcc 版本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FROM debian ENV VER 7.2.3 RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install wget make gcc -y \u0026amp;\u0026amp; \\ wget https://download.redis.io/releases/redis-$VER.tar.gz \u0026amp;\u0026amp; \\ tar zxvf redis-$VER.tar.gz \u0026amp;\u0026amp; cd redis-$VER \u0026amp;\u0026amp; \\ make \u0026amp;\u0026amp; mkdir /usr/local/redis \u0026amp;\u0026amp; \\ make install PREFIX=/usr/local/redis \u0026amp;\u0026amp; \\ mkdir -p /usr/local/redis/{conf,bin} \u0026amp;\u0026amp; \\ cp redis.conf /usr/local/redis/conf \u0026amp;\u0026amp; \\ apt-get clean \u0026amp;\u0026amp; apt-get remove -y wget gcc make # 启动 redis CMD [\u0026#34;/usr/local/redis/bin/redis-server\u0026#34;, \u0026#34;/usr/local/redis/conf\u0026#34;] 构造镜像 1 docker build -t redis:one-line-debian -f dockerfile2 . ROOTFS 1 2 3 4 5 6 7 8 9 10 11 docker inspect redis:one-line-debian ...... \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:ae134c61b154341a1dd932bd88cb44e805837508284e5d60ead8e94519eb339f\u0026#34;, \u0026#34;sha256:98547bcc9e3b713c48a4f5ca069fd442eaa71bc61b68c9a3c00a4af0d73cbe2d\u0026#34; ] }, ...... 可以看出将多条指令合并书写能够有效减少 ROOTFS 层数\n使用分段构造 多段构造, 在到最后一段, 有小镜像承接, 前面段的内容不会保留下来\n推荐镜像:\n镜像 说明 scrach 空镜像, 不带任何调试工具 busybox 小镜像, 带有基础调试工具 因为我们需要解压 tar 包, scrath 没有解压工具, 我们使用 busybox 演示\n使用 busybox 作为基础镜像\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 FROM ubuntu:trusty as builder ENV VER 7.2.3 RUN apt update \u0026amp;\u0026amp; \\ apt install wget make gcc -y \u0026amp;\u0026amp; \\ wget https://download.redis.io/releases/redis-$VER.tar.gz \u0026amp;\u0026amp; \\ tar zxvf redis-$VER.tar.gz \u0026amp;\u0026amp; cd redis-$VER \u0026amp;\u0026amp; \\ make \u0026amp;\u0026amp; mkdir /usr/local/redis \u0026amp;\u0026amp; \\ make install PREFIX=/usr/local/redis \u0026amp;\u0026amp; \\ cp redis.conf /usr/local/redis/conf \u0026amp;\u0026amp; \\ apt-get clean \u0026amp;\u0026amp; apt-get remove -y wget gcc make RUN tar cvf /123.tar /usr/local/redis/ FROM busybox COPY --from=builder /123.tar / RUN tar xvf /123.tar -C /usr/local/ # 启动 redis CMD [\u0026#34;/usr/local/redis/bin/redis-server\u0026#34;, \u0026#34;/usr/local/redis/conf\u0026#34;] 构造镜像 补充: 如果你遇到 Dockerfile 构造时的错误时, 可以加上 --progress=plain --no-cache查看详细构建日志\n1 docker build -t redis:with-busybox -f dockerfile7 . --progress=plain ROOTFS 1 2 3 4 5 6 7 8 9 10 11 12 docker inspect redis:with-busybox ...... \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:82ae998286b2bba64ce571578647adcabef93d53867748d6046cc844ff193a83\u0026#34;, \u0026#34;sha256:335bc67496eb30fe68fe25e6c8f97cb6b74d9989a1c6b24012971097bf22a1a3\u0026#34;, \u0026#34;sha256:abf10e66d6bddcb7e00f41707d71515b1927b1984889aa13ca6b232f9fb78b27\u0026#34; ] }, ...... 镜像压缩 了解即可 docker squash已不在维护\n安装 1 2 3 wget https://github.com/jwilder/docker-squash/releases/download/v0.2.0/docker-squash-linux-amd64-v0.2.0.tar.gz tar xzvf docker-squash-linux-amd64-v0.2.0.tar.gz -C /usr/local/bin/ 使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 root@MKT:~/goproject/httppod/tmp# docker save redis:many-lines-ubuntu | docker-squash -verbose -t redis:squash | docker load Loading export from STDIN using /tmp/docker-squash272131964 for tempdir Loaded image w/ 13 layers - redis (1 tags) Extracting layers... - /tmp/docker-squash272131964/72c5745a74e809afa1c8bbb09164a25a99971cd6ebb60bf9a3c7c399932e2d92/layer.tar - /tmp/docker-squash272131964/e0d139e2e59aa8505f205730d7bd8924bf1289034504be42b618c284420cb9c2/layer.tar - /tmp/docker-squash272131964/10bc199db63a91cf1c3d75fddb1083740e09115320801e0e34f517f8160bd326/layer.tar - /tmp/docker-squash272131964/228aa3e189d788785b2d8c129b6bbf1553ad34e141608706f2d0459d5a1be035/layer.tar - /tmp/docker-squash272131964/42f6beebfd61e1ff415ab2237fdb49bd34dee9f319a1d49e2ca525dc18823e5d/layer.tar - /tmp/docker-squash272131964/45ce59804d1f796310cf5ba3e5878be2e63d644ba271c8d33a315230e737324f/layer.tar - /tmp/docker-squash272131964/462272b123320a876d404d41dac9f20ecf24140f22d979896cc2d0bfa487bae2/layer.tar - /tmp/docker-squash272131964/63b9671bfe8674a1e65dfbb88881ddb1c214eabf89f6ed98e3f0e1deaca9bd8f/layer.tar - /tmp/docker-squash272131964/075972677a1d485c0ba03f4d3b2fb6e3c39f273628f6f0d702149faa4e2831bd/layer.tar - /tmp/docker-squash272131964/88f0016636d34b6a24606c2db4d7ea26c0a02d830383e46aee831c2e1db897a9/layer.tar - /tmp/docker-squash272131964/a8626ef4bd7f2ec2fde454e5263f09eea4d369983ef770abb470f1688baa6681/layer.tar - /tmp/docker-squash272131964/a8ea63a42a3c2e60d8738e8bd81be0502d4bc6ecc827c8e472e171d4abf7e5cf/layer.tar - /tmp/docker-squash272131964/b795b8b69dcd58cbf17a234cba5e8d1de61da850032d781ae92b3ba9eb0fdb69/layer.tar Inserted new layer 2619184f193f after 228aa3e189d7 - 228aa3e189d7 -\u0026gt; 2619184f193f /bin/sh -c #(squash) from 228aa3e189d7 - 075972677a1d - 10bc199db63a - a8626ef4bd7f - 88f0016636d3 - e0d139e2e59a - 63b9671bfe86 - 45ce59804d1f - 462272b12332 - b795b8b69dcd - 42f6beebfd61 - a8ea63a42a3c - 72c5745a74e8 Squashing from 2619184f193f into 2619184f193f - Deleting whiteouts for layer 075972677a1d - Deleting whiteouts for layer 10bc199db63a Removing extracted layers Tagging 2619184f193f as redis:squash Tarring new image to STDOUT Done. New image created. - 228aa3e189d7 54.036378 years 206.1 MB - 2619184f193f 17 seconds /bin/sh -c #(squash) from 228aa3e189d7 370.1 MB Removing tempdir /tmp/docker-squash272131964 Loaded image: redis:many-lines-ubuntu 总结 镜像大小\n1 2 3 4 5 6 7 root@MKT:~/goproject/httppod/tmp# docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis with-busybox a26dc68d9da9 17 minutes ago 65.1MB busybox copy-on-write e71e45a955a2 26 minutes ago 109MB redis many-lines-ubuntu cf3ded3f5a5f 43 minutes ago 565MB redis one-line-debian ac157643d4a6 About an hour ago 669MB redis one-line-ubuntu 86be0695bcf2 2 hours ago 562MB 精简镜像方式:\n使用单条指令替换多条指令 使用更小的基础镜像 使用镜像压缩工具 参考:\n容器化 | 使用 Alpine 构建 Redis 镜像 - RadonDB - 博客园 (cnblogs.com) 基于alpine用dockerfile创建的nginx镜像 - 一本正经的搞事情 - 博客园 (cnblogs.com) redis二进制安装_二进制安装redis-CSDN博客 apt get - Debian 8 Jessie archive.debian.org GPG error KEYEXPIRED since 2022-11-19 (what now?) - Stack Overflow ","date":"2024-01-01T15:01:35+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/%E7%B2%BE%E7%AE%80%E9%95%9C%E5%83%8F/cover.jpg","permalink":"/p/dockerfile-%E5%88%B6%E4%BD%9C%E7%B2%BE%E7%AE%80%E9%95%9C%E5%83%8F/","title":"Dockerfile: 制作精简镜像"},{"content":"问题场景: k8s 1.28.1\n集群后期新增 vip\napiserver 证书不支持 vip\n第二个 master 节点想要加入集群, 但是在 etcd 健康检查时, 实现 vip 不在 apiserver 证书范围内\n1 2 3 4 5 6 7 8 [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [check-etcd] Checking that the etcd cluster is healthy error execution phase check-etcd: could not retrieve the list of etcd endpoints: Get \u0026#34;https://11.0.1.100:16443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Detcd%2Ctier%3Dcontrol-plane\u0026#34;: tls: failed to verify certificate: x509: certificate is valid for 10.96.0.1, 11.0.1.150, not 11.0.1.100 To see the stack trace of this error execute with --v=5 or higher 问题分析: 说明 api-server 的证书没有添加 11.0.1.100\n问题解决: 查看 apiserver 证书支持的 ip 或 host 1 2 3 4 5 openssl x509 -noout -text -in /etc/kubernetes/pki/apiserver.crt 输出: X509v3 Subject Alternative Name: DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, DNS:master1, IP Address:10.96.0.1, IP Address:11.0.1.150 说明当前 apiserver 不支持 vip 11.0.1.100 的连接\n使用 openssl 生成证书: 1 2 3 4 5 6 7 8 9 10 11 12 mkdir /tmp/bak cp /etc/kubernetes/pki/ /tmp/bak/ -r # 生成密钥对 cd /etc/kubernetes/pki/ openssl genrsa -out apiserver.key 2048\t# 新增 apiserver.ext文件，包含所有的地址列表，以及新增地址 subjectAltName = DNS:wudang,DNS:kubernetes,DNS:kubernetes.default,DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, IP:10.96.0.1, IP:11.0.1.150, IP:11.0.1.100 # 生成 openssl req -new -key apiserver.key -subj \u0026#34;/CN=kube-apiserver,\u0026#34; -out apiserver.csr 再次查看 apiserver 证书支持的 ip 或 host 1 2 3 4 5 6 openssl x509 -noout -text -in apiserver.crt 输出: X509v3 extensions: X509v3 Subject Alternative Name: DNS:wudang, DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, IP Address:10.96.0.1, IP Address:11.0.1.150, IP Address:11.0.1.100 可以看到 11.0.1.100 已经成功加上去了\n再次尝试将 master 加点加入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 root@ubuntu:/etc/kubernetes/pki# kubeadm join 11.0.1.150:6443 --token iwqftg.rs9wydqac98ecqbv --discovery-token-ca-cert-hash sha256:698fef4be22b563ce3ae350971e8ca1302488eda76148df5c210a03ce29c0b1a --control-plane --certificate-key c994991c3445a3dc03fbe4f0d8794e8e51946a2b44c920c9a74fa5941b03261d [preflight] Running pre-flight checks [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -o yaml\u0026#39; [preflight] Running pre-flight checks before initializing the new control plane instance [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; W1230 19:00:20.797222 23382 checks.go:835] detected that the sandbox image \u0026#34;registry.aliyuncs.com/google_containers/pause:3.8\u0026#34; of the container runtime is inconsistent with that used by kubeadm. It is recommended that using \u0026#34;registry.aliyuncs.com/google_containers/pause:3.9\u0026#34; as the CRI sandbox image. [download-certs] Downloading the certificates in Secret \u0026#34;kubeadm-certs\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [download-certs] Saving the certificates to the folder: \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master2] and IPs [10.96.0.1 11.0.1.151 11.0.1.100] [certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost master2] and IPs [11.0.1.151 127.0.0.1 ::1] [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost master2] and IPs [11.0.1.151 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Valid certificates and keys now exist in \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Using the existing \u0026#34;sa\u0026#34; key [kubeconfig] Generating kubeconfig files [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; W1230 19:00:21.802963 23382 endpoint.go:57] [endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file W1230 19:00:22.105107 23382 endpoint.go:57] [endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file W1230 19:00:22.181303 23382 endpoint.go:57] [endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [check-etcd] Checking that the etcd cluster is healthy [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Starting the kubelet [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... [etcd] Announced new etcd member joining to the existing etcd cluster [etcd] Creating static Pod manifest for \u0026#34;etcd\u0026#34; [etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s The \u0026#39;update-status\u0026#39; phase is deprecated and will be removed in a future release. Currently it performs no operation [mark-control-plane] Marking the node master2 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node master2 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule] This node has joined the cluster and a new control plane instance was created: * Certificate signing request was sent to apiserver and approval was received. * The Kubelet was informed of the new secure connection details. * Control plane label and taint were applied to the new node. * The Kubernetes control plane instances scaled up. * A new etcd member was added to the local/stacked etcd cluster. To start administering your cluster from this node, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Run \u0026#39;kubectl get nodes\u0026#39; to see this node join the cluster. 新增的 master 节点成功加入集群\n参考 Kubernetes学习(解决x509 certificate is valid for xxx, not yyy) | Z.S.K.\u0026rsquo;s Records (izsk.me) 解决 Kubeadm 添加新 Master 节点到集群出现 ETCD 健康检查失败错误_error execution phase check-etcd: etcd cluster is -CSDN博客 https://cloud.tencent.com/developer/article/1692388 ","date":"2023-12-30T20:10:27+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/%E6%89%A9%E5%B1%95%20apiserver%20%E8%BF%9E%E6%8E%A5%E8%AE%A4%E8%AF%81%20ip/cover.png","permalink":"/p/%E6%89%A9%E5%B1%95-apiserver-%E8%BF%9E%E6%8E%A5%E8%AE%A4%E8%AF%81-ip-%E8%AF%81%E4%B9%A6%E6%9B%B4%E6%96%B0/","title":"扩展 apiserver 连接认证 ip, 证书更新"},{"content":"集群配置 配置清单 OS： ubuntu 20.04 kubernetes： 1.28.1 Container Runtime：Containerd 1.7.11 CRI: runc 1.10 CNI: cni-plugin 1.4 集群规划 IP Host 配置 11.0.1.147 master1 (keepalived+nginx) 2C 4G 30G 11.0.1.148 master2 (keepalived+nginx) 2C 4G 30G 11.0.1.149 node1 2C 4G 30G 11.0.1.150 node2 2C 4G 30G 11.0.1.151 node3 2C 4G 30G 集群网络规划 Pod 网络: 10.244.0.0/16 Service 网络: 10.96.0.0/12 Node 网络: 11.0.1.0/24 安装配置 keepalived 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # 在规划的 vip 节点 apt install keepalived -y # master1 cat \u0026gt; /etc/keepalived/keepalived.conf \u0026lt;\u0026lt; EOF ! Configuration File for keepalived global_defs { router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 } vrrp_instance VI_1 { state MASTER interface ens33 virtual_router_id 50 priority 100 advert_int 1 authentication { auth_type PASS auth_pass root } virtual_ipaddress { 11.0.1.100 } } EOF # master2 cat \u0026gt; /etc/keepalived/keepalived.conf \u0026lt;\u0026lt; EOF ! Configuration File for keepalived global_defs { router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 } vrrp_instance VI_1 { state BACKUP interface ens33 virtual_router_id 50 nopreempt priority 70 advert_int 1 virtual_ipaddress { 11.0.1.100 } } EOF # 重启 keepalived systemctl restart keepalived.service \u0026amp;\u0026amp; systemctl enable keepalived.service systemctl status keepalived.service # 查看 vip ip a | grep 11.0.1.100 # 可停掉 master1 看 vip 是否会漂移到 master2 安装配置 nginx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 apt install nginx -y systemctl status nginx # 修改 nginx 配置文件 cat /etc/nginx/nginx.conf user user; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/*.conf; events { worker_connections 768; # multi_accept on; } #添加了stream 这一段，其他的保持默认即可 stream { log_format main \u0026#39;$remote_addr $upstream_addr - [$time_local] $status $upstream_bytes_sent\u0026#39;; access_log /var/log/nginx/k8s-access.log main; upstream k8s-apiserver { server 11.0.1.147:6443; #master01的IP和6443端口 server 11.0.1.148:6443; #master02的IP和6443端口 } server { listen 16443; #监听的是16443端口，因为nginx和master复用机器，所以不能是6443端口 proxy_pass k8s-apiserver; #使用proxy_pass模块进行反向代理 } } http { ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } # 重启 nginx 服务 systemctl restart nginx \u0026amp;\u0026amp; systemctl enable nginx \u0026amp;\u0026amp; systemctl status nginx # 端口检查 netstat -lntup| grep 16443 配置高可用 ApiServer 可以使用 kubeadm init 初始化集群时, 指定高可用地址 command line 1 2 3 4 5 6 7 8 kubeadm init \\ --apiserver-advertise-address=11.0.1.147 \\ --apiserver-bind-port=6443 \\ --control-plane-endpoint=11.0.1.100:16443 \\ # 指定 vip + nginx 端口 --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.28.1 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 yaml 方式初始化 kubeadm 初始化集群文件 Kubernetes-cluster.yaml:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: # 将此处IP地址替换为主节点IP ETCD容器会试图通过此地址绑定端口 如果主机不存在则会失败 advertiseAddress: 11.0.1.147 bindPort: 6443 nodeRegistration: criSocket: unix:///run/containerd/containerd.sock imagePullPolicy: IfNotPresent name: master1 # 节点 hostname taints: null --- # controlPlaneEndpoint 可配置高可用的 ApiServer apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 controlPlaneEndpoint: 11.0.1.100:6443 # 使用 keepalived + nginx 的高可用地址 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: # 可使用外接 etcd 集群 local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers # 国内源 kind: ClusterConfiguration kubernetesVersion: 1.28.1 networking: dnsDomain: cluster.local # 增加配置 指定pod网段 podSubnet: \u0026#34;10.244.0.0/16\u0026#34; serviceSubnet: 10.96.0.0/12 scheduler: {} --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration mode: ipvs # kubeproxy 使用 ipvs --- kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 cgroupDriver: systemd 在已有集群上添加高可用地址 1 2 3 kubectl -n kube-system edit cm kubeadm-config # 把 controlPlaneEndpoint 修改为高可用地址即可 单 master 转 vip 高可用的坑:\n如果遇到加入新节点时, 出现 tls 相关报错, 显示连接 ip 不支持, 则需要更新 apiserver 证书\n","date":"2023-12-24T20:48:26+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/keepalived%2Bnginx%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8apiserver/cover.png","permalink":"/p/keepalived-nginx%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8apiserver/","title":"Keepalived+nginx实现高可用apiserver"},{"content":"集群配置 配置清单 OS： ubuntu 20.04 kubernetes： 1.28.1 Container Runtime：Containerd 1.7.11 CRI: runc 1.10 CNI: cni-plugin 1.4 集群规划 IP Hostname 配置 11.0.1.147 master1 2C 4G 30G 11.0.1.148 master2 2C 4G 30G 11.0.1.149 node1 2C 4G 30G 11.0.1.150 node2 2C 4G 30G 11.0.1.151 node3 2C 4G 30G 集群网络规划 Pod 网络: 10.244.0.0/16 Service 网络: 10.96.0.0/12 Node 网络: 11.0.1.0/24 环境初始化 主机配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 修改主机名 hostnamectl set-hostname master1 hostnamectl set-hostname master2 hostnamectl set-hostname node1 hostnamectl set-hostname node2 hostnamectl set-hostname node3 # 将节点加入 hosts cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; /etc/hosts 11.0.1.147 master1 11.0.1.148 master2 11.0.1.149 node1 11.0.1.150 node2 11.0.1.151 node3 EOF # 时间同步 timedatectl set-timezone Asia/Shanghai #安装chrony，联网同步时间 apt install chrony -y \u0026amp;\u0026amp; systemctl enable --now chronyd # 配置 ssh 免密登录 ssh-copy-id -i /root/.ssh/id_rsa.pub root@11.0.1.148 ssh-copy-id -i /root/.ssh/id_rsa.pub root@11.0.1.149 ssh-copy-id -i /root/.ssh/id_rsa.pub root@11.0.1.150 ssh-copy-id -i /root/.ssh/id_rsa.pub root@11.0.1.151 禁用 swap 1 sudo swapoff -a \u0026amp;\u0026amp; sed -i \u0026#39;/swap/s/^/#/\u0026#39; /etc/fstab 安装 ipvs 1 apt install -y ipset ipvsadm 调整内核参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # 配置需要的内核模块 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF # 启动模块 sudo modprobe overlay sudo modprobe br_netfilter cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF # 是 sysctl 参数生效 sudo sysctl --system # 检验是否配置成功 lsmod | grep br_netfilter lsmod | grep overlay sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward # 配置 ipvs 内核参数 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/ipvs.conf ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh nf_conntrack EOF # 内核加载 ipvs sudo modprobe ip_vs sudo modprobe ip_vs_rr sudo modprobe ip_vs_wrr sudo modprobe ip_vs_sh sudo modprobe nf_conntrack # 确认ipvs模块加载 lsmod |grep -e ip_vs -e nf_conntrack 安装 Containerd 二进制安装 containerd 1 2 3 4 5 6 7 8 9 10 11 wget -c https://github.com/containerd/containerd/releases/download/v1.7.11/containerd-1.7.11-linux-amd64.tar.gz tar -xzvf containerd-1.7.11-linux-amd64.tar.gz #解压出来一个bin目录,containerd可执行文件都在bin目录里面 mv bin/* /usr/local/bin/ rm -rf bin #使用systemcd来管理containerd wget https://raw.githubusercontent.com/containerd/containerd/main/containerd.service mv containerd.service /usr/lib/systemd/system/ systemctl daemon-reload \u0026amp;\u0026amp; systemctl enable --now containerd systemctl status containerd 安装 OCI Interface runc 1 2 3 4 #安装runc #runc是容器运行时，runc实现了容器的init，run，create，ps...我们在运行容器所需要的cmd： curl -LO https://github.com/opencontainers/runc/releases/download/v1.1.10/runc.amd64 \u0026amp;\u0026amp; \\ install -m 755 runc.amd64 /usr/local/sbin/runc 安装 CNI plugins 1 2 3 4 wget -c https://github.com/containernetworking/plugins/releases/download/v1.4.0/cni-plugins-linux-amd64-v1.4.0.tgz #根据官网的安装步骤来，创建一个目录用于存放cni插件 mkdir -p /opt/cni/bin tar -xzvf cni-plugins-linux-amd64-v1.4.0.tgz -C /opt/cni/bin/ 修改 Containd 配置 1 2 3 4 5 6 7 8 9 10 11 12 #修改containerd的配置，因为containerd默认从k8s官网拉取镜像 #创建一个目录用于存放containerd的配置文件 mkdir -p /etc/containerd #把containerd配置导出到文件 containerd config default | sudo tee /etc/containerd/config.toml # 修改沙箱镜像 sed -i \u0026#39;s#sandbox_image = \u0026#34;registry.k8s.io/pause:3.8\u0026#34;#sandbox_image = \u0026#34;registry.aliyuncs.com/google_containers/pause:3.8\u0026#34;#\u0026#39; /etc/containerd/config.toml # 修改 cgroup 为 systemd sed -i \u0026#39;s#SystemdCgroup = false#SystemdCgroup = true#\u0026#39; /etc/containerd/config.toml # 配置镜像加速 sed -i \u0026#39;s#config_path = \u0026#34;\u0026#34;#config_path = \u0026#34;/etc/containerd/certs.d\u0026#34;#\u0026#39; /etc/containerd/config.toml 配置 Containerd 镜像源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 # docker hub镜像加速 mkdir -p /etc/containerd/certs.d/docker.io cat \u0026gt; /etc/containerd/certs.d/docker.io/hosts.toml \u0026lt;\u0026lt; EOF server = \u0026#34;https://docker.io\u0026#34; [host.\u0026#34;https://dockerproxy.com\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;] [host.\u0026#34;https://docker.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;] [host.\u0026#34;https://reg-mirror.qiniu.com\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;] [host.\u0026#34;https://registry.docker-cn.com\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;] [host.\u0026#34;http://hub-mirror.c.163.com\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;] EOF # registry.k8s.io镜像加速 mkdir -p /etc/containerd/certs.d/registry.k8s.io tee /etc/containerd/certs.d/registry.k8s.io/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://registry.k8s.io\u0026#34; [host.\u0026#34;https://k8s.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # docker.elastic.co镜像加速 mkdir -p /etc/containerd/certs.d/docker.elastic.co tee /etc/containerd/certs.d/docker.elastic.co/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://docker.elastic.co\u0026#34; [host.\u0026#34;https://elastic.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # gcr.io镜像加速 mkdir -p /etc/containerd/certs.d/gcr.io tee /etc/containerd/certs.d/gcr.io/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://gcr.io\u0026#34; [host.\u0026#34;https://gcr.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # ghcr.io镜像加速 mkdir -p /etc/containerd/certs.d/ghcr.io tee /etc/containerd/certs.d/ghcr.io/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://ghcr.io\u0026#34; [host.\u0026#34;https://ghcr.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # k8s.gcr.io镜像加速 mkdir -p /etc/containerd/certs.d/k8s.gcr.io tee /etc/containerd/certs.d/k8s.gcr.io/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://k8s.gcr.io\u0026#34; [host.\u0026#34;https://k8s-gcr.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # mcr.m.daocloud.io镜像加速 mkdir -p /etc/containerd/certs.d/mcr.microsoft.com tee /etc/containerd/certs.d/mcr.microsoft.com/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://mcr.microsoft.com\u0026#34; [host.\u0026#34;https://mcr.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # nvcr.io镜像加速 mkdir -p /etc/containerd/certs.d/nvcr.io tee /etc/containerd/certs.d/nvcr.io/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://nvcr.io\u0026#34; [host.\u0026#34;https://nvcr.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # quay.io镜像加速 mkdir -p /etc/containerd/certs.d/quay.io tee /etc/containerd/certs.d/quay.io/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://quay.io\u0026#34; [host.\u0026#34;https://quay.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # registry.jujucharms.com镜像加速 mkdir -p /etc/containerd/certs.d/registry.jujucharms.com tee /etc/containerd/certs.d/registry.jujucharms.com/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://registry.jujucharms.com\u0026#34; [host.\u0026#34;https://jujucharms.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF # rocks.canonical.com镜像加速 mkdir -p /etc/containerd/certs.d/rocks.canonical.com tee /etc/containerd/certs.d/rocks.canonical.com/hosts.toml \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server = \u0026#34;https://rocks.canonical.com\u0026#34; [host.\u0026#34;https://rocks-canonical.m.daocloud.io\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;, \u0026#34;push\u0026#34;] EOF #重启containerd systemctl restart containerd systemctl status containerd 创建容器确保 containerd 正确运行(可选) 1 2 3 4 5 6 7 8 #拉取镜像，测试containerd是否能创建和启动成功 ctr i pull docker.io/library/nginx:alpine\t#能正常拉取镜像说明没啥问题 ctr images ls\t#查看镜像 ctr c create --net-host docker.io/library/nginx:alpine nginx #创建容器 ctr task start -d nginx\t#启动容器，正常说明containerd没啥问题 ctr containers ls #查看容器 ctr tasks kill -s SIGKILL nginx\t#终止容器 ctr containers rm nginx\t#删除容器 安装 kubeadm、kubelet、kubectl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 安装依赖 apt install apt-transport-https ca-certificates -y apt install vim lsof net-tools zip unzip tree wget curl bash-completion pciutils gcc make lrzsz tcpdump bind9-utils -y # 编辑镜像源文件，文件末尾加入阿里云k8s镜像源配置 echo \u0026#39;deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main\u0026#39; \u0026gt;\u0026gt; /etc/apt/sources.list #更新证书 curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add #更新源 apt update # 查看 kubeadm 版本 apt-cache madison kubeadm | grep 1.28 apt-get install -y kubeadm=1.28.1-00 kubectl=1.28.1-00 kubelet=1.28.1-00 # kubelet 开机自启 systemctl enable kubelet 配置 crictl socket 1 2 crictl config runtime-endpoint unix:///run/containerd.sock crictl config image-endpoint unix:///run/containerd/containerd.sock kubeadm init 一: 直接通过 kubeadm init 初始化集群 可提前拉取镜像 1 2 kubeadm config images list --kubernetes-version=v1.28.1 --image-repository=registry.aliyuncs.com/google_containers kubeadm config images pull --kubernetes-version=v1.28.1 --image-repository=registry.aliyuncs.com/google_containers 初始化集群 以下是安装是非高可用这并不影响高可用的配置, 我另一篇博客 keepalived+nginx实现高可用apiserver, 初始化集群与高可用的 apiserver 两步骤可以完全独立, 这两篇博客带你了解 kubeadm init 的多种方式\n1 2 3 4 5 6 kubeadm init \\ --apiserver-advertise-address=11.0.1.147 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.28.1 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 二: 通过加载配置文件初始化集群 获取集群初始化配置文件 1 2 kubeadm config print init-defaults \u0026gt;Kubernetes-cluster.yaml vim Kubernetes-cluster.yaml Kubernetes-cluster.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: # 将此处IP地址替换为主节点IP ETCD容器会试图通过此地址绑定端口 如果主机不存在则会失败 advertiseAddress: 11.0.1.147 bindPort: 6443 nodeRegistration: criSocket: unix:///run/containerd/containerd.sock imagePullPolicy: IfNotPresent name: master1 # 节点 hostname taints: null --- # controlPlaneEndpoint 可配置高可用的 ApiServer apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: # 可使用外接 etcd 集群 local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers # 国内源 kind: ClusterConfiguration kubernetesVersion: 1.28.1 networking: dnsDomain: cluster.local # 增加配置 指定pod网段 podSubnet: \u0026#34;10.244.0.0/16\u0026#34; serviceSubnet: 10.96.0.0/12 scheduler: {} --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration mode: ipvs # kubeproxy 使用 ipvs --- kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 cgroupDriver: systemd 获取或修改: kubectl -n kube-system edit cm kubeadm-config\n使用配置文件初始化集群 1 kubeadm init --config Kubernetes-cluster.yaml 复制 kubeconfig 1 2 3 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 加入节点 加入 工作节点 可直接复制 kubeadm init 后的 join 加入\n1 2 kubeadm join 11.0.1.147:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:7b465a19bae495131a16b51967a0c329bce9fe7d49136c641929eda69cfd6969 加入 master 如果 kubeadm init 后有加入 master 的命令直接复制就行\n如果没有就自己创建 control-plane 的 cert\n创建 cert-key 1 2 3 $ kubeadm init phase upload-certs --upload-certs [upload-certs] Using certificate key: d38fbc73dc4c113409597a59d65ee66e4641ca220a463b1efeac9baa14f2924a 创建 token 也可以直接用 kubeadm init 产生的 token 1 2 $ kubeadm token create --print-join-command kubeadm join 11.0.1.147:6443 --token m4l8th.81p28vmm5dh3nxl9 --discovery-token-ca-cert-hash sha256:7b465a19bae495131a16b51967a0c329bce9fe7d49136c641929eda69cfd6969 加入 master2 1 kubeadm join 11.0.1.147:6443 --token m4l8th.81p28vmm5dh3nxl9 --discovery-token-ca-cert-hash sha256:7b465a19bae495131a16b51967a0c329bce9fe7d49136c641929eda69cfd6969 --control-plane --certificate-key d38fbc73dc4c113409597a59d65ee66e4641ca220a463b1efeac9baa14f2924a 排错\n如何向Kubernetes集群中添加master节点（原集群只有一个master节点）\n1 2 3 4 5 6 7 8 9 10 11 12 [preflight] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -o yaml\u0026#39; error execution phase preflight: One or more conditions for hosting a new control plane instance is not satisfied. unable to add a new control plane instance to a cluster that doesn\u0026#39;t have a stable controlPlaneEndpoint address Please ensure that: * The cluster has a stable controlPlaneEndpoint address. * The certificates that must be shared among control plane instances are provided. To see the stack trace of this error execute with --v=5 or higher 说明 apiserver 没有绑定到固定 IP, 可以在 master1\n1 2 3 kubectl -n kube-system edit cm kubeadm-config # 修改 data 中 controlPlaneEndpoint 为一个静态 IP(要确保静态 IP 能够访问 apiserver 注意证书, 后期可通过 keepalived/nginx 配置 apiserver 的高可用, 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 root@ubuntu:~# kubeadm join 11.0.1.147:6443 --token m4l8th.81p28vmm5dh3nxl9 --discovery-token-ca-cert-hash sha256:7b465a19bae495131a16b51967a0c329bce9fe7d49136c641929eda69cfd6969 --control-plane --certificate-key d38fbc73dc4c113409597a59d65ee66e4641ca220a463b1efeac9baa14f2924a [preflight] Running pre-flight checks [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -o yaml\u0026#39; [preflight] Running pre-flight checks before initializing the new control plane instance [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; W1223 14:04:19.065758 16517 checks.go:835] detected that the sandbox image \u0026#34;registry.aliyuncs.com/google_containers/pause:3.8\u0026#34; of the container runtime is inconsistent with that used by kubeadm. It is recommended that using \u0026#34;registry.aliyuncs.com/google_containers/pause:3.9\u0026#34; as the CRI sandbox image. [download-certs] Downloading the certificates in Secret \u0026#34;kubeadm-certs\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [download-certs] Saving the certificates to the folder: \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost master2] and IPs [11.0.1.148 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost master2] and IPs [11.0.1.148 127.0.0.1 ::1] [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master2] and IPs [10.96.0.1 11.0.1.148 11.0.1.147] [certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Valid certificates and keys now exist in \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Using the existing \u0026#34;sa\u0026#34; key [kubeconfig] Generating kubeconfig files [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [check-etcd] Checking that the etcd cluster is healthy [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Starting the kubelet [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... [etcd] Announced new etcd member joining to the existing etcd cluster [etcd] Creating static Pod manifest for \u0026#34;etcd\u0026#34; [etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s The \u0026#39;update-status\u0026#39; phase is deprecated and will be removed in a future release. Currently it performs no operation [mark-control-plane] Marking the node master2 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node master2 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule] This node has joined the cluster and a new control plane instance was created: * Certificate signing request was sent to apiserver and approval was received. * The Kubelet was informed of the new secure connection details. * Control plane label and taint were applied to the new node. * The Kubernetes control plane instances scaled up. * A new etcd member was added to the local/stacked etcd cluster. To start administering your cluster from this node, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Run \u0026#39;kubectl get nodes\u0026#39; to see this node join the cluster. 配置命令行自动补全(可选) 1 2 3 4 5 6 7 8 apt install bash-completion -y cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; ~/.profile alias k=\u0026#39;kubectl\u0026#39; source \u0026lt;(kubectl completion bash) complete -F __start_kubectl k EOF source ~/.profile 安装 calico 1 2 3 4 kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml wget https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml vi custom-resources.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # This section includes base Calico installation configuration. # For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.Installation apiVersion: operator.tigera.io/v1 kind: Installation metadata: name: default spec: # Configures Calico networking. calicoNetwork: # Note: The ipPools section cannot be modified post-install. ipPools: - blockSize: 26 cidr: 10.244.0.0/16 # 与划分的 pod 网段一致 encapsulation: VXLANCrossSubnet natOutgoing: Enabled nodeSelector: all() --- # This section configures the Calico API server. # For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.APIServer apiVersion: operator.tigera.io/v1 kind: APIServer metadata: name: default spec: {} 验证集群 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 root@ubuntu:~# k get po -A NAMESPACE NAME READY STATUS RESTARTS AGE calico-apiserver calico-apiserver-66cb6b4b7f-8l67s 1/1 Running 0 57s calico-apiserver calico-apiserver-66cb6b4b7f-p8xs9 0/1 Running 0 57s calico-system calico-kube-controllers-86d48c97dc-vzzcd 1/1 Running 0 5m32s calico-system calico-node-29snn 1/1 Running 0 5m32s calico-system calico-node-cqrrf 1/1 Running 0 5m32s calico-system calico-node-gvpjn 1/1 Running 0 5m32s calico-system calico-node-wq4mh 1/1 Running 0 5m32s calico-system calico-node-xfvkw 1/1 Running 0 5m32s calico-system calico-typha-55fd77b9db-2x8sv 1/1 Running 0 5m24s calico-system calico-typha-55fd77b9db-4r98k 1/1 Running 0 5m33s calico-system calico-typha-55fd77b9db-qk7cm 1/1 Running 0 5m24s calico-system csi-node-driver-bhzpm 2/2 Running 0 5m32s calico-system csi-node-driver-bptcd 2/2 Running 0 5m32s calico-system csi-node-driver-g884s 2/2 Running 0 5m32s calico-system csi-node-driver-vm4p7 0/2 ContainerCreating 0 5m32s calico-system csi-node-driver-zgmds 2/2 Running 0 5m32s kube-system coredns-66f779496c-6fmh9 1/1 Running 0 17h kube-system coredns-66f779496c-p47zp 1/1 Running 0 17h kube-system etcd-master1 1/1 Running 2 17h kube-system etcd-master2 1/1 Running 0 16h kube-system kube-apiserver-master1 1/1 Running 2 17h kube-system kube-apiserver-master2 1/1 Running 0 16h kube-system kube-controller-manager-master1 1/1 Running 4 17h kube-system kube-controller-manager-master2 1/1 Running 1 (11h ago) 16h kube-system kube-proxy-bb2qd 1/1 Running 0 17h kube-system kube-proxy-c4zqw 1/1 Running 0 17h kube-system kube-proxy-cnwnl 1/1 Running 0 16h kube-system kube-proxy-mtgn6 1/1 Running 0 17h kube-system kube-proxy-tlgln 1/1 Running 0 17h kube-system kube-scheduler-master1 1/1 Running 4 17h kube-system kube-scheduler-master2 1/1 Running 1 (11h ago) 16h tigera-operator tigera-operator-55585899bf-mcs5f 1/1 Running 0 5m46s root@ubuntu:~# k get no NAME STATUS ROLES AGE VERSION master1 Ready control-plane 17h v1.28.1 master2 Ready control-plane 16h v1.28.1 node1 Ready \u0026lt;none\u0026gt; 17h v1.28.1 node2 Ready \u0026lt;none\u0026gt; 17h v1.28.1 node3 Ready \u0026lt;none\u0026gt; 17h v1.28.1 参考文章: 将 Docker Engine 节点从 dockershim 迁移到 cri-dockerd | Kubernetes 使用 kubeadm 引导集群 | Kubernetes ubuntu安装指定版本docker(包含官方/国内安装方法)_ubuntu 18.04 安装docker 20.10.7-CSDN博客 ubuntu 20.4安装k8s 1.24.0、1.28.0（使用containerd）_ubuntu containerd 安装-CSDN博客 kubeadm 部署k8s v1.28.3集群 - 小吉猫 - 博客园 (cnblogs.com) 如何向Kubernetes集群中添加master节点（原集群只有一个master节点） - 知乎 (zhihu.com) [containerd] 镜像加速_containerd 镜像加速-CSDN博客 ","date":"2023-12-24T15:08:15+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/基于 containerd 部署k8s 1.28.1 (Ubuntu 20.04)/cover.png","permalink":"/p/%E5%9F%BA%E4%BA%8E-containerd-%E9%83%A8%E7%BD%B2k8s-1.28.1-ubuntu-20.04/","title":"基于 Containerd 部署k8s 1.28.1 (Ubuntu 20.04)"},{"content":"主机规划 主机 IP node1 11.0.1.144 node2 11.0.1.145 node3 11.0.1.146 确保 Go 版本 1.15+\netcd 集群证书 安装 cfssl 1 apt install golang-cfssl -y 生成默认证书 1 2 cfssl print-defaults config \u0026gt; ca-config.json cfssl print-defaults crs \u0026gt; ca-crs.json 修改证书 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 root@ubuntu:~/tls# cat ca-config.json { \u0026#34;signing\u0026#34;: { \u0026#34;default\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;876000h\u0026#34; }, \u0026#34;profiles\u0026#34;: { \u0026#34;etcdha\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;876000h\u0026#34;, \u0026#34;usages\u0026#34;: [ \u0026#34;signing\u0026#34;, \u0026#34;key encipherment\u0026#34;, \u0026#34;client auth\u0026#34;, \u0026#34;server auth\u0026#34; ] } } } } root@ubuntu:~/tls# cat ca-csr.json { \u0026#34;CN\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;etcd\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;xian\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;chengdu\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;system\u0026#34; } ] } 生成 CA 证书 1 cfssl gencert -initca ca-csr.json | cfssljson -bare ca 创建 etcd 证书签名请求（etcd-csr.json) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 root@ubuntu:~/tls# cat etcd-csr.json { \u0026#34;CN\u0026#34;: \u0026#34;etcd\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;127.0.0.1\u0026#34;, \u0026#34;11.0.1.144\u0026#34;, \u0026#34;11.0.1.145\u0026#34;, \u0026#34;11.0.1.146\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;etcdha\u0026#34; } ] } 使用 ca 证书签发 etcd 证书 1 2 3 4 cfssl gencert -ca ca.pem -ca-key ca-key.pem -config ca-config.json -profile etcdha etcd-csr.json | cfssljson -bare etcd root@ubuntu:~/tls# ls ca-config.json ca.csr ca-csr.json ca-key.pem ca.pem etcd.csr etcd-csr.json etcd-key.pem etcd.pem 复制证书 1 2 3 4 5 6 7 mkdir /opt/etcd -p cp etcd*.pem ca*.pem /opt/etcd/ssl/ cd /opt/etcd/ssl # 确保事先有相应目录 scp *.pem root@11.0.1.145:/opt/etcd/ssl/ scp *.pem root@11.0.1.146:/opt/etcd/ssl/ etcd HA 部署 安装 etcd 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ETCD_VER=v3.5.11 # choose either URL GOOGLE_URL=https://storage.googleapis.com/etcd GITHUB_URL=https://github.com/etcd-io/etcd/releases/download DOWNLOAD_URL=${GOOGLE_URL} rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz rm -rf /tmp/etcd-download-test \u0026amp;\u0026amp; mkdir -p /tmp/etcd-download-test curl -L ${DOWNLOAD_URL}/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz -o /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz tar xzvf /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz -C /tmp/etcd-download-test --strip-components=1 rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz /tmp/etcd-download-test/etcd --version /tmp/etcd-download-test/etcdctl version /tmp/etcd-download-test/etcdutl version mv /tmp/etcd-download-test/etcd /bin/ mv /tmp/etcd-download-test/etcdctl /bin/ mv /tmp/etcd-download-test/etcdutl /bin/ 分别在各个节点启动 etcd node1:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 nohup etcd --name infra0 \\ --data-dir=/tmp/etcd/infra0 \\ --listen-peer-urls https://11.0.1.144:2380 \\ --initial-advertise-peer-urls https://11.0.1.144:2380 \\ --listen-client-urls https://11.0.1.144:2379 \\ --advertise-client-urls https://11.0.1.144:2379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster infra0=https://11.0.1.144:2380,infra1=https://11.0.1.145:2380,infra2=https://11.0.1.146:2380 \\ --initial-cluster-state new \\ --client-cert-auth --trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --cert-file=/opt/etcd/ssl/etcd.pem \\ --key-file=/opt/etcd/ssl/etcd-key.pem \\ --peer-client-cert-auth --peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --peer-cert-file=/opt/etcd/ssl/etcd.pem \\ --peer-key-file=/opt/etcd/ssl/etcd-key.pem 2\u0026gt;\u0026amp;1 \u0026gt; /var/log/infra0.log \u0026amp; node2:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 nohup etcd --name infra1 \\ --data-dir=/tmp/etcd/infra1 \\ --listen-peer-urls https://11.0.1.145:2380 \\ --initial-advertise-peer-urls https://11.0.1.145:2380 \\ --listen-client-urls https://11.0.1.145:2379 \\ --advertise-client-urls https://11.0.1.145:2379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster infra0=https://11.0.1.144:2380,infra1=https://11.0.1.145:2380,infra2=https://11.0.1.146:2380 \\ --initial-cluster-state new \\ --client-cert-auth --trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --cert-file=/opt/etcd/ssl/etcd.pem \\ --key-file=/opt/etcd/ssl/etcd-key.pem \\ --peer-client-cert-auth --peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --peer-cert-file=/opt/etcd/ssl/etcd.pem \\ --peer-key-file=/opt/etcd/ssl/etcd-key.pem 2\u0026gt;\u0026amp;1 \u0026gt; /var/log/infra1.log \u0026amp; node3:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 nohup etcd --name infra2 \\ --data-dir=/tmp/etcd/infra2 \\ --listen-peer-urls https://11.0.1.146:2380 \\ --initial-advertise-peer-urls https://11.0.1.146:2380 \\ --listen-client-urls https://11.0.1.146:2379 \\ --advertise-client-urls https://11.0.1.146:2379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-cluster infra0=https://11.0.1.144:2380,infra1=https://11.0.1.145:2380,infra2=https://11.0.1.146:2380 \\ --initial-cluster-state new \\ --client-cert-auth --trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --cert-file=/opt/etcd/ssl/etcd.pem \\ --key-file=/opt/etcd/ssl/etcd-key.pem \\ --peer-client-cert-auth --peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --peer-cert-file=/opt/etcd/ssl/etcd.pem \\ --peer-key-file=/opt/etcd/ssl/etcd-key.pem 2\u0026gt;\u0026amp;1 \u0026gt; /var/log/infra2.log \u0026amp; 查看集群状态 1 2 3 4 5 6 7 8 root@ubuntu:/opt/etcd/ssl# etcdctl --endpoints=https://11.0.1.144:2379 --cacert /opt/etcd/ssl/ca.pem --cert /opt/etcd/ssl/etcd.pem --key /opt/etcd/ssl/etcd-key.pem member list -wtable +------------------+---------+--------+-------------------------+-------------------------+------------+ | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER | +------------------+---------+--------+-------------------------+-------------------------+------------+ | 68e936a39e332ee | started | infra1 | https://11.0.1.145:2380 | https://11.0.1.145:2379 | false | | 65d6166ada62ab60 | started | infra0 | https://11.0.1.144:2380 | https://11.0.1.144:2379 | false | | 8a036567f69e370a | started | infra2 | https://11.0.1.146:2380 | https://11.0.1.146:2379 | false | +------------------+---------+--------+-------------------------+-------------------------+------------+ etcd 集群备份与恢复 插入数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 root@ubuntu:~# etcdctl --endpoints=https://11.0.1.144:2379 --cacert /opt/etcd/ssl/ca.pem --cert /opt/etcd/ssl/etcd.pem --key /opt/etcd/ssl/etcd-key.pem put /test1 val1 OK root@ubuntu:~# etcdctl --endpoints=https://11.0.1.144:2379 --cacert /opt/etcd/ssl/ca.pem --cert /opt/etcd/ssl/etcd.pem --key /opt/etcd/ssl/etcd-key.pem put /test2 val2 OK root@ubuntu:~# etcdctl --endpoints=https://11.0.1.144:2379 --cacert /opt/etcd/ssl/ca.pem --cert /opt/etcd/ssl/etcd.pem --key /opt/etcd/ssl/etcd-key.pem put /test1/t1 val1/v1 OK root@ubuntu:~# etcdctl --endpoints=https://11.0.1.144:2379 --cacert /opt/etcd/ssl/ca.pem --cert /opt/etcd/ssl/etcd.pem --key /opt/etcd/ssl/etcd-key.pem get --prefix /test /test1 val1 /test1/t1 val1/v1 /test2 val2 备份 etcd 数据 1 2 3 4 etcdctl --endpoints=https://11.0.1.144:2379 --cacert /opt/etcd/ssl/ca.pem --cert /opt/etcd/ssl/etcd.pem --key /opt/etcd/ssl/etcd-key.pem snapshot save /tmp/snapshot.db scp /tmp/snapshot.db root@11.0.1.145:/tmp/ scp /tmp/snapshot.db root@11.0.1.146:/tmp/ 杀掉个节点 etcd 进程 1 2 ps -ef | grep infra | grep -v grep | awk \u0026#39;{print $2}\u0026#39; | xargs kill -9 ps -ef | grep etcd 删除 etcd 数据 1 rm -rf /tmp/etcd 恢复 etcd 数据 node1:\n1 2 3 4 5 6 7 export ETCDCTL_API=3 etcdctl snapshot restore /tmp/snapshot.db \\ --name infra0 \\ --data-dir=/tmp/etcd/infra0 \\ --initial-cluster infra0=https://11.0.1.144:2380,infra1=https://11.0.1.145:2379,infra2=https://11.0.1.146:2379 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-advertise-peer-urls https://11.0.1.144:2380 node2:\n1 2 3 4 5 6 7 export ETCDCTL_API=3 etcdctl snapshot restore /tmp/snapshot.db \\ --name infra1 \\ --data-dir=/tmp/etcd/infra1 \\ --initial-cluster infra0=https://11.0.1.144:2380,infra1=https://11.0.1.145:2380,infra2=https://11.0.1.146:2380 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-advertise-peer-urls https://11.0.1.145:2380 node3:\n1 2 3 4 5 6 7 export ETCDCTL_API=3 etcdctl snapshot restore /tmp/snapshot.db \\ --name infra2 \\ --data-dir=/tmp/etcd/infra2 \\ --initial-cluster infra0=https://11.0.1.144:2380,infra1=https://11.0.1.145:2380,infra2=https://11.0.1.146:2380 \\ --initial-cluster-token etcd-cluster-1 \\ --initial-advertise-peer-urls https://11.0.1.146:2380 重启 etcd node1:\n1 2 3 4 5 6 7 8 9 10 11 nohup etcd --name infra0 \\ --data-dir=/tmp/etcd/infra0 \\ --listen-peer-urls https://11.0.1.144:2380 \\ --listen-client-urls https://11.0.1.144:2379 \\ --advertise-client-urls https://11.0.1.144:2379 \\ --client-cert-auth --trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --cert-file=/opt/etcd/ssl/etcd.pem \\ --key-file=/opt/etcd/ssl/etcd-key.pem \\ --peer-client-cert-auth --peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --peer-cert-file=/opt/etcd/ssl/etcd.pem \\ --peer-key-file=/opt/etcd/ssl/etcd-key.pem 2\u0026gt;\u0026amp;1 \u0026gt; /var/log/infra0.log \u0026amp; node2:\n1 2 3 4 5 6 7 8 9 10 11 nohup etcd --name infra1 \\ --data-dir=/tmp/etcd/infra1 \\ --listen-peer-urls https://11.0.1.145:2380 \\ --listen-client-urls https://11.0.1.145:2379 \\ --advertise-client-urls https://11.0.1.145:2379 \\ --client-cert-auth --trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --cert-file=/opt/etcd/ssl/etcd.pem \\ --key-file=/opt/etcd/ssl/etcd-key.pem \\ --peer-client-cert-auth --peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --peer-cert-file=/opt/etcd/ssl/etcd.pem \\ --peer-key-file=/opt/etcd/ssl/etcd-key.pem 2\u0026gt;\u0026amp;1 \u0026gt; /var/log/infra1.log \u0026amp; node3:\n1 2 3 4 5 6 7 8 9 10 11 nohup etcd --name infra2 \\ --data-dir=/tmp/etcd/infra2 \\ --listen-peer-urls https://11.0.1.146:2380 \\ --listen-client-urls https://11.0.1.146:2379 \\ --advertise-client-urls https://11.0.1.146:2379 \\ --client-cert-auth --trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --cert-file=/opt/etcd/ssl/etcd.pem \\ --key-file=/opt/etcd/ssl/etcd-key.pem \\ --peer-client-cert-auth --peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --peer-cert-file=/opt/etcd/ssl/etcd.pem \\ --peer-key-file=/opt/etcd/ssl/etcd-key.pem 2\u0026gt;\u0026amp;1 \u0026gt; /var/log/infra2.log \u0026amp; 查看集群状态 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 root@ubuntu:/tmp# etcdctl --endpoints=https://11.0.1.146:2379 --cacert /opt/etcd/ssl/ca.pem --cert /opt/etcd/ssl/etcd.pem --key /opt/etcd/ssl/etcd-key.pem member list -wtable +------------------+-----------+--------+-------------------------+-------------------------+------------+ | ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER | +------------------+-----------+--------+-------------------------+-------------------------+------------+ | 68e936a39e332ee | started | infra1 | https://11.0.1.145:2380 | https://11.0.1.145:2379 | false | | 65d6166ada62ab60 | unstarted | | https://11.0.1.144:2380 | | false | | 8a036567f69e370a | started | infra2 | https://11.0.1.146:2380 | https://11.0.1.146:2379 | false | +------------------+-----------+--------+-------------------------+-------------------------+------------+ root@ubuntu:/tmp# etcdctl --endpoints=https://11.0.1.146:2379 --cacert /opt/etcd/ssl/ca.pem --cert /opt/etcd/ssl/etcd.pem --key /opt/etcd/ssl/etcd-key.pem get --prefix / /test1 val1 /test1/t1 val1/v1 /test2 val2 infra0未启动成功, 其余两个节点正常, 原因未知, 待大佬指正\n参考:\netcd使用Cfssl生成自签证书(pem) - 西瓜君~ - 博客园 (cnblogs.com) [svc]证书各个字段的含义 - _毛台 - 博客园 (cnblogs.com) ","date":"2023-12-20T18:25:32+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/etcd高可用集群部署/cover.png","permalink":"/p/etcd%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","title":"Etcd高可用集群部署"},{"content":"Dockerfile 目标：易管理、少漏洞、镜像小、层级少、利用缓存。 Dockerfile 最佳实践 不要安装无效软件包。\n应简化镜像中同时运行的进程数，理想状况下，每个镜像应该只有一个进程。\n当无法避免同一镜像运行多进程时，应选择合理的初始化进程（initprocess）。\n最小化层级数\n最新的docker只有RUN，COPY，ADD创建新层，其他指令创建临时层，不会增加镜像大小。 比如EXPOSE指令就不会生成新层。 多条RUN命令可通过连接符连接成一条指令集以减少层数。 通过多段构建减少镜像层数。 把多行参数按字母排序，可以减少可能出现的重复参数，并且提高可读性。\n编写dockerfile的时候，应该把变更频率低的编译指令优先构建以便放在镜像底层以有效利用buildcache。\n复制文件时，每个文件应独立复制，这确保某个文件变更时，只影响改文件对应的缓存。\n理解 Dockerfile Dockerfile 可以看成构建镜像的一条条指令, 结合 docker 镜像打包理解, 一条指令大多对应一层, 追求共用层\n层的概念:\ndocker build 构建镜像 1 $ docker build [选项] \u0026lt;上下文路径/URL/-\u0026gt; 通过 docker build 构建镜像会自动扫描 Dockerfile 及其目录下的子目录, 通常将 Dockerfile 置于项目根目录, 如果文件文件过多, 镜像过程也会变慢\nDockerfile 常用指令 From 指定镜像, 默认从 docker hub 上拉去\nLABEL 用于为镜像添加元数据\n1 格式: LABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... 配合 label filter 进行过滤\n1 $ docker images -f label=multi.label1=\u0026#34;value1\u0026#34; 注： 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据 之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。\nENV 设置环境变量\nRUN 构建镜像时执行的命令\n1 2 3 4 5 6 格式： RUN [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] 示例： RUN [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] RUN apk update RUN [\u0026#34;/etc/execfile\u0026#34;, \u0026#34;arg1\u0026#34;, \u0026#34;arg1\u0026#34;] 注：RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像， 可以在构建时指定\u0026ndash;no-cache参数，如：docker build \u0026ndash;no-cache\nCMD 构建镜像后调用，也就是在容器启动时才进行调用。\n1 2 3 4 5 6 7 格式： CMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] (执行可执行文件，优先) CMD [\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数) CMD command param1 param2 (执行shell内部命令) 示例： CMD echo \u0026#34;This is a test.\u0026#34; | wc -l CMD [\u0026#34;/usr/bin/wc\u0026#34;,\u0026#34;--help\u0026#34;] 注：CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令。\nENTRYPOINT 镜像的第一个进程\n1 2 3 4 5 6 7 8 格式： ENTRYPOINT [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] (可执行文件, 优先) ENTRYPOINT command param1 param2 (shell内部命令) 示例： FROM ubuntu ENTRYPOINT [\u0026#34;ls\u0026#34;, \u0026#34;/usr/local\u0026#34;] CMD [\u0026#34;/usr/local/tomcat\u0026#34;] 之后，docker run 传递的参数，都会先覆盖cmd,然后由cmd 传递给entrypoint ,做到灵活应用 注：ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT， 而docker run命令中指定的任何参数，都会被当做参数再次传递给CMD。 Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置， 而只执行最后的ENTRYPOINT指令。 通常情况下，\tENTRYPOINT 与CMD一起使用，ENTRYPOINT 写默认命令，当需要参数时候 使用CMD传参\nDockerfile: ENTRYPOINT和CMD的区别 - 知乎 (zhihu.com)\nWORKDIR 工作目录，类似于cd命令\nADD 将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget\n1 2 3 4 5 6 7 8 格式： ADD \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; ADD [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 用于支持包含空格的路径 示例： ADD hom* /mydir/ # 添加所有以\u0026#34;hom\u0026#34;开头的文件 ADD hom?.txt /mydir/ # ? 替代一个单字符,例如：\u0026#34;home.txt\u0026#34; ADD test relativeDir/ # 添加 \u0026#34;test\u0026#34; 到 `WORKDIR`/relativeDir/ ADD test /absoluteDir/ # 添加 \u0026#34;test\u0026#34; 到 /absoluteDir/ COPY 与 ADD 相似, 但不能访问网络资源, 也不能解压, 以 ADD 相比, 行为简单, 因此可控, 推荐使用\nVOLUME 挂载\n1 2 3 4 VOLUME [\u0026#34;/path/to/dir\u0026#34;] 示例: VOLUME [\u0026#34;/data\u0026#34;] VOLUME [\u0026#34;/var/www\u0026#34;, \u0026#34;/var/log/apache2\u0026#34;, \u0026#34;/etc/apache2\u0026#34; 注：一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能：\n卷可以容器间共享和重用 容器并不一定要和其它容器共享卷 修改卷后会立即生效 对卷的修改不会对镜像产生影响 卷会一直存在，直到没有任何容器在使用它 EXPOSE 暴露端口\n1 EXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;...] 注：EXPOSE并不会让容器的端口访问到主机。要使其可访问，需要在docker run运行容器时通过-p来发布这些端口，或通过-P参数来发布EXPOSE导出的所有端口 如果没有暴露端口，后期也可以通过-p 8080:80方式映射端口，但是不能通过-P形式映射\nUSER 指定运行容器的用户/组, 不指定默认 root, 指定的 Dockerfile 中其后的命令RUN、CMD、ENTRYPOINT都将使用该用户, 增强容器的安全性考虑, 做到 POLP(最小特权原则)。\n注： 镜像构建完成后，通过docker run运行容器时，可以通过-u参数来覆盖所指定的用户。\nARG 用于指定传递给构建运行时的变量(给dockerfile传参)，相当于构建镜像时可以在外部为里面传参\n1 2 3 4 5 6 7 8 9 From centos:7 ARG parameter VOLUME /usr/share/nginx RUN yum -y install $parameter EXPOSE 80 443 CMD nginx -g \u0026#34;daemon off;\u0026#34; # 可以这如下这样灵活传参 docker build --build-arg=parameter=net-tools -t nginx:01 . Dockerfile 模版 二进制构建 nginx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # Base images 基础镜像 FROM centos #MAINTAINER 维护者信息 MAINTAINER Ai-feier #ENV 设置环境变量 ENV PATH /usr/local/nginx/sbin:$PATH #ADD 文件放在当前目录下，拷过去会自动解压 ADD nginx-1.8.0.tar.gz /usr/local/ ADD epel-release-latest-7.noarch.rpm /usr/local/ #RUN 执行以下命令 RUN rpm -ivh /usr/local/epel-release-latest-7.noarch.rpm RUN yum install -y wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre \u0026amp;\u0026amp; yum clean all RUN useradd -s /sbin/nologin -M www #WORKDIR 相当于cd WORKDIR /usr/local/nginx-1.8.0 RUN ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-pcre \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install RUN echo \u0026#34;daemon off;\u0026#34; \u0026gt;\u0026gt; /etc/nginx.conf #EXPOSE 映射端口 EXPOSE 80 #CMD 运行以下命令 CMD [\u0026#34;nginx\u0026#34;] apt 构建 nginx 1 2 3 4 5 6 # Base images 基础镜像 FROM ubuntu RUN apt-get update \u0026amp;\u0026amp; apt-get install nginx -y \u0026amp;\u0026amp; apt-get clean CMD [\u0026#34;nginx\u0026#34;] 构建springboot应用 1 2 3 4 5 6 7 8 FROM openjdk:8-jre # jar包基于jdk ,war包基于tomcat WORKDIR /app ADD demo-0.0.1-SNAPSHOT.jar app.jar # 将上下文中 jar包复制到 /app目录下，并且重命名为app.jar EXPOSE 8081 # 暴露端口 ENTRYPOINT[ \u0026#34;java\u0026#34; , \u0026#34;-jar\u0026#34; ] # 启动应用固定命令 CMD [\u0026#34;app.jar\u0026#34;] # 动态传递jar包名 # CMD [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;java -jar app.jar\u0026#34;] 在 k8s 优雅终止时, 会发送 terminal 信号, 给应用进行优雅终止, 但是, /bin/sh 会无视这个信号, 最后直接被 kill 掉\nDockerfile 多段构造 目的: 将项目编译, 依赖等, 放到 Dockerfile 的早期构建, 最后留下一个干净的镜像, 有效减少镜像层级\n示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 FROM golang:1.16-alpine AS build RUN apkadd --no-cache git RUN go get github.com/golang/dep/cmd/dep COPY Gopkg.lock Gopkg.toml /go/src/project/ WORKDIR /go/src/project/ RUN dep ensure -vendor-only COPY . /go/src/project/ RUN go build -o /bin/project（只有这个二进制文件是产线需要的，其他都是waste） FROM scratch # 直接把镜像编译的包拷贝下来 COPY --from=build /bin/project /bin/project ENTRYPOINT [\u0026#34;/bin/project\u0026#34;] CMD [\u0026#34;--help\u0026#34;] ","date":"2023-12-18T02:12:07+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/Dockerfile/cover.png","permalink":"/p/dockerfile/","title":"Dockerfile"},{"content":"docker 网络模式 模式 说明 Null(\u0026ndash;net=None) 把容器放入独立网络空间, 但不做网络配置 Host 复用主机网络 Container 重用其他容器网络 Bridge docker 容器创建的默认模式, 容器通过 veth pair 连接到 docker0 网桥 veth pair 可跨 net namespace\nBridge docker 创建容器的默认模式\n创建 veth pair 将 veth pair 的一端连接到 docker0 veth pair 另一端设置为容器的 eth0 为容器明空间的 eth0 分配 ip 主机的 Iptables 规则: PREROUTING-A DOCKER ! -idocker0 -p tcp-m tcp\u0026ndash;dport 2333 -j DNAT \u0026ndash;to destination 172.17.0.2:22 解释: 如果你的协议是 tcp, 目标端口是 2333, 就转到 容器 172.17.0.2 的 22 端口\n为 Null 模式重新配置网络 Create network ns 1 2 mkdir -p /var/run/netns find -L /var/run/netns -type l -delete Start nginx docker with non network mode 1 docker run --network=none -d nginx Check corresponding pid 1 2 3 4 5 6 docker ps|grep nginx docker inspect \u0026lt;containerid\u0026gt;|grep -i pid \u0026#34;Pid\u0026#34;: 876884, \u0026#34;PidMode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;PidsLimit\u0026#34;: null, Check network config for the container 1 2 3 4 5 6 nsenter -t 558754 -n ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever Link network namespace 1 2 3 export pid=558754 ln -s /proc/$pid/ns/net /var/run/netns/$pid ip netns list Check docker bridge on the host 1 2 3 4 5 6 7 8 brctl show ip a 4: docker0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:35:40:d3:8b brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:35ff:fe40:d38b/64 scope link valid_lft forever preferred_lft forever Create veth pair 1 ip link add A type veth peer name B Config A 1 2 brctl addif docker0 A ip link set A up Config B 1 2 3 4 5 6 7 8 9 SETIP=172.17.0.10 SETMASK=16 GATEWAY=172.17.0.1 ip link set B netns $pid ip netns exec $pid ip link set dev B name eth0 ip netns exec $pid ip link set eth0 up ip netns exec $pid ip addr add $SETIP/$SETMASK dev eth0 ip netns exec $pid ip route add default via $GATEWAY Check connectivity 1 curl 172.17.0.10 容器的多主机间通信 Underlay 为容器的预留一端 IP, 主机就清楚其 IP 的路由, 则能解决主机间容器的互通\nOverlay 隧道模式, 为数据包多封装一层, 在对端主机解包\n","date":"2023-12-18T02:11:39+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/docker网络/cover.png","permalink":"/p/docker%E7%BD%91%E7%BB%9C/","title":"Docker网络"},{"content":"grep 语法格式:\ngrep [option] [pattern] [file1, file2] command | grep [option] [pattern] grep 参数:\n参数 含义 -v 不显示匹配信息 -i 忽略大小写 -n 显示行号 -r 递归搜索 -E 支持扩展正则表达式 (egrep) -F 不按正则表达式匹配 以下为不常用参数 -c 只显示匹配行总数 -w 匹配整词 -x 匹配整行 -l 只显示文件名, 不显示内容 -s 不显示错误信息 1 2 3 4 5 $ grep \u0026#39;py.*\u0026#39; file # grep 支持正则表达式 $ grep -E \u0026#34;python|PYTHON\u0026#34; file # 支持扩展正则表达式 $ grep -F \u0026#34;py.*\u0026#34; file # 会按原始语义搜索 egrep egrep 与 grep -E 等价\n1 2 3 $ grep -E \u0026#39;python|PYTHON\u0026#39; file $ egrep \u0026#39;python|PYTHON\u0026#39; file ","date":"2023-12-17T15:17:00+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/文本处理三剑客之grep/cover.png","permalink":"/p/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bgrep/","title":"文本处理三剑客之grep"},{"content":"sed 工作模式 sed 是流编辑器, 对标准输出文件逐行处理\n匹配 + 执行 : 默认会打印原始信息, 还会打印执行后的结果\n语法格式:\nstdout | sed [option] \u0026ldquo;pattern command\u0026rdquo; sed [optoin] \u0026ldquo;pattern command\u0026rdquo; pattern 是可选的\nsed 参数 选项 含义 -n 静默模式 -e 进行多条匹配规则 -f 使用文件, 文件为匹配规则 -r 支持扩展正则表达式 -i 直接修改文件内容 1 2 3 4 5 6 7 8 9 10 11 $ sed -n \u0026#39;/python/p\u0026#39; set.txt # p 为打印操作 $ sed -n -e \u0026#39;/python/p\u0026#39; -e \u0026#39;/PYTHON/p\u0026#39; sed.txt # 执行多条 # print.sed: /python/p $ sed -n -f print.sed sed.txt $ sed -n -r \u0026#39;/python|PYTHON/p\u0026#39; sed.txt # g: 全部修改; p: 打印到终端; -i 直接修改到文件 $ sed -i \u0026#39;s/love/like/g;p\u0026#39; sed.txt pattern 用法 匹配模式\n匹配模式 含义 10command 匹配第 10 行 10,20command 从第 10 行开始, 到第 20 行结束 10,+5command 从第 10 行开始, 到第 16 行结束 /pattern1/command (//d) 匹配 pattern1 的行 /pattern1/,/pattern2/command (//,//p) 匹配 pattern1 的行开始, 到 pattern2 的行结束 10,/pattern1/command 从第 10 行开始, 到匹配 pattern1 的行结束 /pattern1/,10command 从匹配 pattern1 的行开始, 到第 10 行结束 1 2 3 4 5 6 7 8 9 10 $ sed -n \u0026#39;10p\u0026#39; /etc/passwd $ sed -n \u0026#39;10,20p\u0026#39; /etc/passwd $ sed -n \u0026#39;10,+5p\u0026#39; /etc/passwd $ sed -n \u0026#39;/^root/p\u0026#39; /etc/passwd $ sed -n \u0026#39;/^root/,/^nginx/p\u0026#39; /etc/passwd $ sed -n \u0026#39;/4,/^nginx/p\u0026#39; /etc/passwd $ sed -n \u0026#39;/^root/,10p\u0026#39; /etc/passwd sed 编辑命令 打印 命令 含义 p 打印 1 $ sed \u0026#39;/^root/p\u0026#39; /etc/passwd 删除 命令 含义 d 删除行 1 2 3 $ sed -i \u0026#39;/\\/sbin\\/nologin/d\u0026#39; passwd $ sed -i \u0026#39;/^mail/,/^ftp/d\u0026#39; passwd 增加 命令 含义 a 行后追加 i 行前追加 r 从外部读入文件, 追加到行后 w 把结果写到对应文件 1 2 3 4 5 6 7 $ sed -i \u0026#39;/^root/,/^nginx/a AAAAAA\u0026#39; passwd # 匹配到的每一行后追加 $ sed -i \u0026#39;/^root/,/^nginx/i AAAAAA\u0026#39; passwd # 匹配到的每一行前追加 $ sed -i \u0026#39;/root/,/nginx/r ./list\u0026#39; passwd $ sed -n \u0026#39;/\\/bin\\/bash/w /tmp/login\u0026#39; passwd 显示行号 命令 含义 = 显示行号 1 $ sed \u0026#39;/\\/bin\\/bash/=\u0026#39; passwd 修改 命令 含义 s/旧/新/ 更改每行第一个 s/旧/新/3 更改每行第一个 s/旧/新/3 更改每行所有 s/旧/新/2g 更改每行第 2 开始所有 s/旧/新/ig 更改每行所有, 忽略大小写 1 2 3 4 5 6 7 8 9 $ sed -i \u0026#39;s/HADOOP/hadoop/\u0026#39; file $ sed -i \u0026#39;s/HADOOP/hadoop/2\u0026#39; file $ sed -i \u0026#39;s/HADOOP/hadoop/g\u0026#39; file $ sed -i \u0026#39;s/HADOOP/hadoop/2g\u0026#39; file $ sed -i \u0026#39;s/HADOOP/hadoop/ig\u0026#39; file 反向引用 \u0026amp;与\\1 , \\1需要与()一起使用(部分引用时)\n1 2 3 4 $ sed -i \u0026#39;s/had..../\u0026amp;s/g\u0026#39; file $ sed -i \u0026#39;s/had..../\\1s/g\u0026#39; file $ sed -i \u0026#39;s/\\(had=)..../\\1DOOP/g\u0026#39; file 变量引用 用双引号 用单引号变量 1 2 3 $ sed -i \u0026#34;s/$str1/str2/g\u0026#34; file $ sed -i \u0026#39;s/\u0026#39;$str1\u0026#39;/\u0026#39;$str2\u0026#39;/g\u0026#39; file 脚本练习: 查询 mysql 配置文件 知识点:\n利用sed进行文件查询\n预期:\n1 2 3 4 mysqld\u0026#39;s num: 22 client\u0026#39;s num: 1 mysql\u0026#39;s num: 1 server\u0026#39;s num: 6 思路:\n获取所有段 根据获取的段信息, 获取每一段下的配置项数目 打印结果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #!/bin/bash # FILENAME=\u0026#34;/root/sed/my.ini\u0026#34; # 1. 获取所有段 function get_segments { item=`sed -n \u0026#39;/\\[.*\\]/p\u0026#39; $FILENAME | sed \u0026#39;s/\\[//g\u0026#39; | sed \u0026#39;s/\\]//g\u0026#39;` echo $item } # 2. 根据获取的段信息, 获取每一段下的配置项数目 function count_segment_num { # 根据 sed 的范围匹配 # 根据参数提供段范围匹配 | 去除 [ 开头 | 去除 # 开头 | 去除空行 items=`sed -n \u0026#39;/\\[\u0026#39;$1\u0026#39;\\]/,/\\[.*\\]/p\u0026#39; $FILENAME | grep -v \u0026#34;^\\[\u0026#34; | grep -v \u0026#34;^#\u0026#34; | grep -v \u0026#34;^$\u0026#34;` # 统计所有项 index=0 for item in $items do index=`expr $index + 1` done echo $index } for seg in `get_segments` do item_count=`count_segment_num $seg` echo \u0026#34;${seg}\u0026#39;s num: $item_count\u0026#34; done sed 文本练习 文本删除: 删除空行和注释行\n1 2 3 4 5 6 7 8 $ sed -i \u0026#39;/^#/d\u0026#39; nginx.conf # 删除开头 # $ sed -i \u0026#39;/^$/d\u0026#39; nginx.conf # 删除空行 $ sed -i \u0026#39;/[:blank]*#/d\u0026#39; nginx.conf # 删除 # 前有空格 # 合并写法 $ sed -i \u0026#39;/[:blank]*#/d;/^$/d\u0026#39; nginx.conf 对以非 # 开头行加 *\n1 2 # 非 # : [^#] $ sed -i \u0026#39;s/^[^#]/\\*\u0026amp;/g\u0026#39; nginx.conf 文本查找 匹配到以 root 开始的行, 把 login 改为 LOGIN\n1 sed -i \u0026#39;/^root/s/login/LOGIN/\u0026#39; passwd 修改以 root 开始的行, 到包含 mail 的行, 修改 bin 为 BIN\n1 sed -i \u0026#39;/^root/,/mail/s/bin/BIN/g\u0026#39; passwd 把文本中数字删除\n1 sed -i \u0026#39;s/[0-9]*//g\u0026#39; file 文本追加 根据行号\n1 $ sed -i \u0026#39;3,7/a Append\u0026#39; passwd 匹配到 /bin/bash 的行, 气候追加 After\n1 $ sed -i \u0026#39;/\\/bin\\/bash/a After\u0026#39; passwd 以 nginx 开头的行前, 添加 Before\n1 $ sed -i \u0026#39;/^nginx/i Before\u0026#39; passwd 每一行前加 Before\n1 $ sed -i \u0026#39;i Before\u0026#39; passwd 把 /etc/fstab 内容追加到含 /bin/bash 的行后\n1 $ sed -i \u0026#39;/\\/bin\\/bash/r /etc/fstab\u0026#39; passwd **把 /bin/bash 的行, 写入 /tmp/sed.txt **\n1 $ sed -i \u0026#39;/\\bin\\/bash/w /tmp/sed.txt\u0026#39; passwd 把第 10 行到以 nginx 开头的行写入 /tmp/sed.txt\n1 $ sed -i \u0026#39;10,/\\bin\\/bash/w /tmp/sed.txt\u0026#39; passwd ","date":"2023-12-17T15:16:34+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/文本处理三剑客之sed/cover.webp","permalink":"/p/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed/","title":"文本处理三剑客之sed"},{"content":"awk 工作模式 与 sed 相同, 都是逐行处理\n语法格式 awk \u0026lsquo;BEGIN{}pattern{commands}END{} filename\u0026rsquo; stdout | awk \u0026lsquo;BEGIN{}pattern{commands}END{}\u0026rsquo; 语法格式 说明 BEGIN{} 处理文本前执行 pattern 匹配模式 {commands} 处理命令, ;隔开 END{} 处理文本后执行 BEGIN{}, pattern, END{} 多可省略\n内置变量 内置变量 含义 $0 整行内容 $1-$n 按分隔符的第 1-n 个字段 NF (Number Field) 当前行的字段个数(多少列) NR (Number Row) 当前行行号, 从 1 开始计数 FNR (File Number Row) 多文件处理时, 每个文件单独技术, 从 1 开始 FS (Field Separate) 输入字段分隔符, 不指定为空格或 tab RS (Row Separator) 输入行分隔符, 默认回车 OFS (Output Field Separator) 输出字段分隔符 ORS (Output Row Separator) 输出行分隔符, 默认回车 FILENAME 当前输入文件名 ARGC 命令行参数个数 ARGV 命令行参数数组 基本使用:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ awk \u0026#39;{print $0}\u0026#39; passwd $ awk \u0026#39;{print $1,$3}\u0026#39; list $ awk \u0026#39;{print NF}\u0026#39; list $ awk \u0026#39;{print NR}\u0026#39; list $ awk \u0026#39;{print FNR}\u0026#39; list awk.txt $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{print $1}\u0026#39; passwd $ awk \u0026#39;BEGIN{RS=\u0026#34;--\u0026#34;}{print $0}\u0026#39; list $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;;OFS=\u0026#34;|\u0026#34;}{print $1,$3}\u0026#39; passwd # 每行输出字段 $ awk \u0026#39;BEGIN{ORS=\u0026#34;--\u0026#34;}{print $0}\u0026#39; passwd $ awk \u0026#39;{print FILENAME}\u0026#39; passwd $ awk \u0026#39;{print ARGC}\u0026#39; passwd list # 3 个参数 awk, passwd, list 格式化输出 printf 格式符 含义 %s 字符串 %d 十进制 %f 浮点数 %x 十六进制 %o 八进制 %e 科学计数法 %c 单个字符 修饰符:\n修饰符 含义 - 左对齐 + 右对齐 # 打印 十六进制与八进制时使用, 在前打印进制标识 示例\n1 2 3 4 5 6 7 8 9 10 11 12 # %s: 默认左对齐 # %10s: 默认右对齐 $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%s\u0026#34;,$7}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%10s\u0026#34;,$7}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%-10s\u0026#34;,$7}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%d\u0026#34;,$3}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%0.3f\u0026#34;,$3}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%x\u0026#34;,$3}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%#x\u0026#34;,$3}\u0026#39; passwd # 显示 16 进制标识 $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%0\u0026#34;,$3}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}{printf \u0026#34;%e\u0026#34;,$3}\u0026#39; passwd 模式匹配 正则表达式 (固定写法//) 关系运算匹配 正则表达式:****\n1 2 3 4 # 含有 root 的行 $ awk \u0026#39;BEGIN{FS=\u0026#39;:\u0026#39;}/root/{print $0}\u0026#39; passwd # 以 nginx 开头 $ awk \u0026#39;BEGIN{FS=\u0026#39;:\u0026#39;}/^nginx/{print $0}\u0026#39; passwd 关系运算符:\n关系运算符 含义 \u0026lt; 数值 小于 \u0026gt; 数值 大于 \u0026lt;= 数值 小于等于 \u0026gt;= 数值 大于等于 == 等于 != 不等于 ~ 匹配正则 !~ 不匹配正则 1 2 3 4 5 6 7 8 9 # 第 3 个字段小于 50 $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}$3\u0026lt;50{print $0}\u0026#39; passwd # 第 7 个字段为 /bin/bash $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}$7==\u0026#34;/bin/bash\u0026#34;{print $0}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}$7!=\u0026#34;/bin/bash\u0026#34;{print $0}\u0026#39; passwd # 第 3 个字段包含 3 个及以上数字 $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}$3~/[0-9]{3,}/{print $0}\u0026#39; passwd 逻辑运算符:\n逻辑运算符 含义 || 或 \u0026amp;\u0026amp; 与 ! 非 1 2 3 $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}$1==\u0026#34;root\u0026#34;||$1==\u0026#34;nginx\u0026#34;{print $0}\u0026#39; passwd $ awk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;}$3\u0026lt;50 \u0026amp;\u0026amp; $3 \u0026gt;30 {print $0}\u0026#39; passwd awk 算数运算 运算符 含义 + 加 - 减 * 乘 / 除 % 取余 ^ 或 ** 乘方 x++ ; x\u0026ndash; 先返回 x, 后 +/- x ++x ; \u0026ndash;x 先 +/- x, 后 返回 x 练习计算课程平均值\n1 2 3 4 # 右对齐 $ awk \u0026#39;BEGIN{printf \u0026#34;%10s%10s%10s%10s%10s\\n\u0026#34;,\u0026#34;Name\u0026#34;, \u0026#34;YuWen\u0026#34;,\u0026#34;ShuXue\u0026#34;, \u0026#34;English\u0026#34;, \u0026#34;AVG\u0026#34;}{total=$1+$2+$3;AVG=total/3;printf \u0026#34;%10s%10d%10d%10d%10.2f\\n\u0026#34;,$1,$2,$3,$4,AVG}\u0026#39; list $ awk \u0026#39;BEGIN{printf \u0026#34;%-10s%-10s%-10s%-10s%-10s\\n\u0026#34;,\u0026#34;Name\u0026#34;, \u0026#34;YuWen\u0026#34;,\u0026#34;ShuXue\u0026#34;, \u0026#34;English\u0026#34;, \u0026#34;AVG\u0026#34;}{total=$1+$2+$3;AVG=total/3;printf \u0026#34;%-10s%-10d%-10d%-10d%-10.2f\\n\u0026#34;,$1,$2,$3,$4,AVG}\u0026#39; list 条件语句 if-else\n示例: script.awk\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 BEGIN{ FS=\u0026#34;:\u0026#34; } { if($3\u0026lt;50) { printf \u0026#34;%-20s%-10s%10d\\n\u0026#34;,\u0026#34;UID\u0026lt;50\u0026#34;,$1,$3 } else if($3\u0026gt;50 \u0026amp;\u0026amp; $3 \u0026lt;100) { printf \u0026#34;%-20s%-10s%10d\\n\u0026#34;,\u0026#34;50\u0026lt;UID\u0026lt;100\u0026#34;,$1,$3 } else { printf \u0026#34;%-20s%-10s%10d\\n\u0026#34;,\u0026#34;UID\u0026gt;100\u0026#34;,$1,$3 } } 1 $ awk -f script.awk /etc/passwd 循环语句 do-while while for 计算 1+2+\u0026hellip;100\ndo-while 1 2 3 4 5 6 7 8 9 BEGIN{ do{ sum += i i++ }while(i\u0026lt;=100) print sum } while 1 2 3 4 5 6 7 8 BEGIN{ while(i\u0026lt;=100) { sum += i i++ } print sum } for 1 2 3 4 5 6 7 8 BEGIN{ for(i=0;i\u0026lt;=100;i++) { sum += i } print sum } 练习: 打印平均分大于 70的, 并计算平均分\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 BEGIN{ printf \u0026#34;%-10s%-10s%-10s%-10s%-10s\\n\u0026#34;,\u0026#34;Name\u0026#34;,\u0026#34;YuWen\u0026#34;,\u0026#34;Math\u0026#34;,\u0026#34;English\u0026#34;,\u0026#34;AVG\u0026#34; } { total = $2 + $3 + $3 avg = total / 3 if (avg \u0026gt; 70) { printf \u0026#34;%-10s%-10d%-10d%-10d%-0.2f\\n\u0026#34;,$1,$2,$3,$4,avg score_yuwen += $2 score_math += $3 score_english += $4 score_avg += avg count++ } } END{ printf \u0026#34;%-10s%-10.2f%-10.2f%-10.2f%-0.2f\\n\u0026#34;,\u0026#34;\u0026#34;,score_yuwen/count,score_math/count,score_english/count,score_avg/count } 字符串函数 函数名 解释 返回值 length(str) 计算字符串长度 长度值 index(str1,str2) 在 str1 中查找 str2 返回位置索引, 从 1 计数 tolower(str) 转小写 转小写后的字符串 toupper(str) 转大写 转大写后的字符串 substr(str,m,n) 从 str m 字符, 截取 n 位(n 可省略) 截取后的子串 split(str,arr,fs) 按 fs 切割字符串, 结果保存到 arr 切割后的子串个数 match(str,RE) 与 index() 类似, 但支持正则(RE) 返回索引位置 sub(RE,RepStr,str) 在 str 中搜索符合 RE 的子串将其替换为 RepStr; 只替换第一个 替换个数 gsub(RE,RepStr,str) 在 str 中搜索符合 RE 的子串将其替换为 RepStr; 替换全部 替换个数 1. 打印 passwd 每个字段长度:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 BEGIN{ FS=\u0026#34;:\u0026#34; } { i=1 while(i\u0026lt;=NF) { if(i==NF) printf \u0026#34;%d\u0026#34;,length($i) else printf \u0026#34;%d:\u0026#34;,length($i) i++ } print \u0026#34;\u0026#34; } 2. 查询\u0026quot;I have a dream\u0026quot;中\u0026quot;ea\u0026quot;索引\n1 2 3 4 $ awk \u0026#39;BEGIN{str=\u0026#34;I have a dream\u0026#34;;localtion=index(str,\u0026#34;ea\u0026#34;);print localtion}\u0026#39; # 12 $ awk \u0026#39;BEGIN{str=\u0026#34;I have a dream\u0026#34;;localtion=match(str,\u0026#34;ea\u0026#34;);print localtion}\u0026#39; # 12 3. 大小写转换\n1 2 3 4 $ awk \u0026#39;BEGIN{str=\u0026#34;I have a dream\u0026#34;;print tolower(str)}\u0026#39; # i have a dream $ awk \u0026#39;BEGIN{str=\u0026#34;I have a dream\u0026#34;;print toupper(str)}\u0026#39; # I HAVE A DREAM 4. 切分数组\n1 2 3 4 5 6 7 8 9 10 $ awk \u0026#39;BEGIN{str=\u0026#34;I have a dream\u0026#34;;split(str,arr,\u0026#34; \u0026#34;);print arr[2]}\u0026#39; $ awk \u0026#39;BEGIN{str=\u0026#34;I have a dream\u0026#34;;split(str,arr);print arr[2]}\u0026#39; # 默认空格分隔 # have # 遍历, 不是顺序遍历 $ awk \u0026#39;BEGIN{str=\u0026#34;I have a dream\u0026#34;;split(str,arr);for(a in arr) print arr[a]}\u0026#39; # dream # I # have # a 5. 搜索第一个出现的数字\n1 2 3 # 正则必须用 // $ awk \u0026#39;BEGIN{str=\u0026#34;I have a 123 dream\u0026#34;; print match(str, /[0-9]/)}\u0026#39; # 10 6. 截取子串\n1 2 3 4 5 $ awk \u0026#39;BEGIN{str=\u0026#34;I have a 123 dream\u0026#34;; print substr(str,3,7)}\u0026#39; # have a $ awk \u0026#39;BEGIN{str=\u0026#34;I have a 123 dream\u0026#34;; print substr(str,3)}\u0026#39; # have a 123 dream 7. 替换数字\n1 2 3 4 5 6 7 $ awk \u0026#39;BEGIN{str=\u0026#34;I have a 123 dream 324 hello\u0026#34;; print sub(/[0-9]+/,\u0026#34;$\u0026#34;,str); print str}\u0026#39; # 1 # I have a $ dream 324 hello $ awk \u0026#39;BEGIN{str=\u0026#34;I have a 123 dream 324 hello\u0026#34;; print gsub(/[0-9]+/,\u0026#34;$\u0026#34;,str); print str}\u0026#39; # 2 # I have a $ dream $ hello awk 常用选项 选项 说明 -v 参数传递 -f 指定脚本文件 -F 指定分隔符 -V 查看版本 如果变量有空格, 要使用\u0026quot;\u0026quot;\n1 2 3 4 5 6 7 8 9 10 $ num=13 $ var=\u0026#34;hello world\u0026#34; $ awk -v num1=$num -v var1=$var \u0026#39;BEGIN{print num1,var1}\u0026#39; # awk: fatal: cannot open file `BEGIN{print num1,var1}\u0026#39; for reading (No such file or directory) $ awk -v num1=\u0026#34;$num\u0026#34; -v var1=\u0026#34;$var\u0026#34; \u0026#39;BEGIN{print num1,var1}\u0026#39; # 13 hello world $ awk -F \u0026#34;:\u0026#34; \u0026#39;{print $0}\u0026#39; /etc/passwd awk 与 shell 中数组 shell 中数组 下标从 0 开始\n打印数组:\n1 2 3 4 5 6 7 8 9 10 $ arr=(\u0026#34;kubernetes\u0026#34; \u0026#34;etcd\u0026#34; \u0026#34;time\u0026#34; \u0026#34;redis\u0026#34;) # 打印数组 $ echo ${arr[@]} $ echo ${arr[*]} # kubernetes etcd time redis # 打印元素 $ echo ${arr[2]} # time 打印数组/元素长度; 分片访问; 元素操作; 删除元素:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 $ arr=(\u0026#34;kubernetes\u0026#34; \u0026#34;etcd\u0026#34; \u0026#34;time\u0026#34; \u0026#34;redis\u0026#34;) # 打印数组 $ echo ${#arr[@]} $ echo ${#arr[*]} # 4 # 打印元素 $ echo ${#arr[3]} # 5 # 分片访问 $ echo ${arr[@]:1:3} # etcd time redis # 元素赋值 $ arr[2]=mysqlserver $ echo ${arr[@]} # kubernetes etcd mysqlserver redis # 元素内容替换 $ echo ${arr[@]/e/E} # kubErnetes Etcd mysqlsErver rEdis $ echo ${arr[@]//e/E} # kubErnEtEs Etcd mysqlsErvEr rEdis # 元素删除 *** 通过下标删除后, 被删除的下标的元素为空, 原数组的其他元素下标不变 $ unset arr[0] $ echo ${arr[@]} # etcd mysqlserver redis $ unset arr[0] $ echo ${arr[@]} # etcd mysqlserver redis $ unset arr[1] $ echo ${arr[@]} # mysqlserver redis # 删除数组 $ unset arr 通过下标删除后, 被删除的下标的元素为空, 原数组的其他元素下标不变\n数组的遍历\n1 2 3 4 5 6 $ arr=(\u0026#34;kubernetes\u0026#34; \u0026#34;etcd\u0026#34; \u0026#34;time\u0026#34; \u0026#34;redis\u0026#34;) $ for a in ${arr[@]}; do echo $a; done # kubernetes # etcd # time # redis awk 中数组 脚本练习 数据生成脚本:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash # function create_random() { min=$1 max=$(($2-$min+1)) num=$(date +%s%N) echo $(($num%$max+min)) } INDEX=1 while true do for user in allen mike jerry tracy han lilei do COUNT=$RANDOM NUM1=`create_random 1 $COUNT` NUM2=`expr $COUNT - $NUM1` echo \u0026#34;`date \u0026#39;+%Y-%m-%d %H:%M:%S\u0026#39;` $INDEX Batches: user $user insert $COUNT records into database:product table:detail, insert $NUM1 records successfully, failed $NUM2 records\u0026#34; \u0026gt;\u0026gt; ./db.log.`date +%Y%m%d` INDEX=`expr $INDEX + 1` done done 数据格式\n1 2 3 4 5 2023-12-12 02:49:31 1 Batches: user allen insert 25719 records into database:product table:detail, insert 24482 records successfully, failed 1237 records 2023-12-12 02:49:31 2 Batches: user mike insert 32653 records into database:product table:detail, insert 26055 records successfully, failed 6598 records 2023-12-12 02:49:31 3 Batches: user jerry insert 16986 records into database:product table:detail, insert 11636 records successfully, failed 5350 records 2023-12-12 02:49:31 4 Batches: user tracy insert 31899 records into database:product table:detail, insert 9250 records successfully, failed 22649 records 2023-12-12 02:49:31 5 Batches: user han insert 24256 records into database:product table:detail, insert 24033 records successfully, failed 223 records 统计所有成功, 失败, 总共记录数\ncount.awk:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 BEGIN{ printf \u0026#34;%-10s%-20s%-20s%-20s\\n\u0026#34;,\u0026#34;User\u0026#34;,\u0026#34;Total\u0026#34;,\u0026#34;Sucess\u0026#34;,\u0026#34;Failed\u0026#34; } { TOTAL[$6]+=$8 SUCESS[$6]+=$14 FAILED[$6]+=$18 } END{ for(t in TOTAL) { total += TOTAL[t] sucess += SUCESS[t] failed += FAILED[t] printf \u0026#34;%-10s%-20s%-20s%-20s\\n\u0026#34;,t,TOTAL[t],SUCESS[t],FAILED[t] } printf \u0026#34;%-10s%-20s%-20s%-20s\\n\u0026#34;,\u0026#34;\u0026#34;,total,sucess,failed } 1 $ awk -f count.awk db.log.20231212 1 2 3 4 5 6 7 8 User Total Sucess Failed tracy 6096344 2963340 3133004 allen 6293470 3182865 3110605 mike 5845083 2912982 2932101 jerry 5996178 3080723 2915455 lilei 6217104 3028971 3188133 han 5923975 3089899 2834076 36372154 18258780 18113374 2. 打印丢失记录的行数\n一条记录行中, 总记录数 != 成功记录数 + 失败记录数\n1 $ awk \u0026#39;{if($8 != $14 + $18) print NR}\u0026#39; db.log.20231212 ","date":"2023-12-17T15:16:07+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/文本处理三剑客之awk/cover.jpg","permalink":"/p/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk/","title":"文本处理三剑客之awk"},{"content":"函数功能划分: 函数定义 函数功能 function get_all_group 获取所有进程组 function get_all_process 获取所有进程 function get_process_info 返回进程详细信息(运行状态, PID, CPU, MEM, 启动时间) function get_all_process_by_group 返回进程组中所有进程名称 函数实现: function get_all_group: 根据对应字段获取其下的所有组名\n1 2 3 4 5 6 7 8 9 10 11 12 13 HOME_DIR=\u0026#34;/root/shell\u0026#34; CONFIG_FILE=\u0026#34;process.cfg\u0026#34; function get_all_group { if [ ! -e $HOME_DIR/$CONFIG_FILE ]; then echo \u0026#34;$CONFIG_FIEL is not exist. Please check...\u0026#34; exit 1 else G_LIST=`sed -n \u0026#39;/\\[GROUP_LIST\\]/,/\\[.*\\]/p\u0026#39; process.cfg | egrep -v \u0026#34;(\\[.*\\]|^$)\u0026#34;` echo \u0026#34;$G_LIST\u0026#34; fi } function get_all_process 遍历所有组, 获取其下的所有进程\n1 2 3 4 5 6 7 function get_all_processes { for g in `get_all_group`;do P_LIST=`sed -n \u0026#39;/\\[\u0026#39;$g\u0026#39;\\]/,/\\[.*\\]/p\u0026#39; process.cfg | egrep -v \u0026#34;^\\[|^$\u0026#34;` echo $P_LIST done } function get_process_info 继续拆分函数, 拆分为 get_process_pid_by_name, get_process_info_by_pid 可直接使用 ps aux 把统计的名称的数据一并处理 get_process_pid_by_name:\n1 2 3 4 5 6 7 8 9 10 11 function get_process_pid_by_name { # 只接受一个参数 if [ $# != 1 ]; then return 1 # 非 0 即为错误 else # 过滤掉脚本本身 pids=`ps -ef | grep \u0026#34;$1\u0026#34; | grep -v grep | grep -v $0 | awk \u0026#39;{print $2}\u0026#39;` echo $pids fi } get_process_info_by_pid:\n1 2 3 4 5 6 7 8 9 10 11 function get_process_info_by_pid { if [ `ps -ef | awk -v p_id=$1 \u0026#39;$2==p_id{print}\u0026#39; | wc -l` == 1 ]; then pro_status=\u0026#34;RUNNING\u0026#34; else pro_status=\u0026#34;STOPED\u0026#34; fi pro_cpu=`ps aux | awk -v p_id=$1 \u0026#39;$2==p_id{print $3}\u0026#39;` pro_mem=`ps aux | awk -v p_id=$1 \u0026#39;$2==p_id{print $4}\u0026#39;` pro_start=\u0026#34;`ps -p $1 -o lstart`\u0026#34; } function get_all_process_by_group 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 function is_group_in_config { for g in `get_all_group`;do if [ \u0026#34;$1\u0026#34; == $g ];then return 0 fi done return 1 } function get_all_processes_by_group { is_group_in_config $1 if [ $? == 0 ];then p_list=`sed -n \u0026#39;/\\[\u0026#39;$1\u0026#39;\\]/,/\\[.*\\]/p\u0026#39; $HOME_DIR/$CONFIG_FILE | egrep -v \u0026#34;(^$|^#|^\\[)\u0026#34;` echo $p_list else echo \u0026#34;GroupName $1 is not in process.cfg\u0026#34; fi } 主流程设计 接受参数 行为 无参数 打印所有信息 -g 组名 接受多个组名, 打印组下所有进程 进程名 打印指定进程名 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 if [ $# -gt 0 ];then if [ $1 == \u0026#34;-g\u0026#34; ];then # 接受组名, 把参数左移, 去掉 -g shift for gn in $@; do is_group_in_config $gn || continue for pn in `get_all_processes_by_group`;do is_process_in_config $pn \u0026amp;\u0026amp; format_print $pn $gn done done else for pn in $@;do is_process_in_config $pn \u0026amp;\u0026amp; format_print $pn $gn done fi else # 没有参数, 打印所有 for pn in `get_all_processes`;do gn=`get_group_by_process_name $pn` is_process_in_config $pn \u0026amp;\u0026amp; format_print $pn $gn done fi 完整脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 #!/bin/bash # # Func: Get app info from process.cfg HOME_DIR=\u0026#34;/root/shell\u0026#34; CONFIG_FILE=\u0026#34;process.cfg\u0026#34; this_pid=$$ function get_all_group { G_LIST=`sed -n \u0026#39;/\\[GROUP_LIST\\]/,/\\[.*\\]/p\u0026#39; process.cfg | egrep -v \u0026#34;(\\[.*\\]|^$)\u0026#34;` echo \u0026#34;$G_LIST\u0026#34; } function get_all_processes { for g in `get_all_group`;do P_LIST=`sed -n \u0026#39;/\\[\u0026#39;$g\u0026#39;\\]/,/\\[.*\\]/p\u0026#39; process.cfg | egrep -v \u0026#34;^\\[|^$\u0026#34;` echo $P_LIST done } function get_process_pid_by_name { # 只接受一个参数 if [ $# != 1 ]; then return 1 # 非 0 即为错误 else pids=`ps -ef | grep \u0026#34;$1\u0026#34; | grep -v grep | grep -v $0 | awk \u0026#39;{print $2}\u0026#39;` echo $pids fi } function get_process_info_by_pid { if [ `ps -ef | awk -v p_id=$1 \u0026#39;$2==p_id{print}\u0026#39; | wc -l` == 1 ]; then pro_status=\u0026#34;RUNNING\u0026#34; else pro_status=\u0026#34;STOPED\u0026#34; fi pro_cpu=`ps aux | awk -v p_id=$1 \u0026#39;$2==p_id{print $3}\u0026#39;` pro_mem=`ps aux | awk -v p_id=$1 \u0026#39;$2==p_id{print $4}\u0026#39;` pro_start_time=\u0026#34;`ps -p $1 -o lstart`\u0026#34; } function is_group_in_config { for g in `get_all_group`;do if [ \u0026#34;$1\u0026#34; == $g ];then return 0 fi done echo \u0026#34;Group $1 is not in process.cfg\u0026#34; return 1 } function get_all_processes_by_group { is_group_in_config $1 if [ $? == 0 ];then p_list=`sed -n \u0026#39;/\\[\u0026#39;$1\u0026#39;\\]/,/\\[.*\\]/p\u0026#39; $HOME_DIR/$CONFIG_FILE | egrep -v \u0026#34;(^$|^#|^\\[)\u0026#34;` echo $p_list else echo \u0026#34;GroupName $1 is not in process.cfg\u0026#34; fi } function format_print { ps -ef | grep $1 | grep -v grep | grep -v $this_pid \u0026amp;\u0026gt; /dev/null if [ $? -eq 0 ]; then pids=`get_process_pid_by_name $1` for pid in $pids; do get_process_info_by_pid $pid awk -v p_name=$1 -v g_name=$2 -v p_id=$pid -v p_status=$pro_status -v p_cpu=$pro_cpu -v p_mem=$pro_mem $p_start_time=\u0026#34;$pro_start_time\u0026#34; \u0026#39;BEGIN{printf \u0026#34;%-10s%-10s%-5s%-5s%-5s%-5s%-15s\u0026#34;,p_name,g_name,p_id,p_status,p_cpu,p_mem,p_start_time}\u0026#39; done else # 进程不存在 awk -v p_name=$1 -v g_name=$2 \u0026#39;BEGIN{printf \u0026#34;%-10s%-10s%-5s%-5s%-5s%-5s%-15s\u0026#34;,p_name,g_name,\u0026#34;NULL\u0026#34;,\u0026#34;STOPED\u0026#34;,\u0026#34;NULL\u0026#34;,\u0026#34;NULL\u0026#34;,\u0026#34;NULL\u0026#34;}\u0026#39; fi } function is_process_in_config { for pn in `get_all_process`;do if [ $pn == $1 ];then return fi done echo \u0026#34;Process $1 is not in process.cfg\u0026#34; return 1 } function get_group_by_process_name { for gn in `get_all_group`;do for pn in `get_all_process_by_group $gn`;do if [ $pn == $1 ]; then ehco $gn fi done done } if [ $# -gt 0 ];then if [ $1 == \u0026#34;-g\u0026#34; ];then # 接受组名, 把参数左移, 去掉 -g shift for gn in $@; do is_group_in_config $gn || continue for pn in `get_all_processes_by_group`;do is_process_in_config $pn \u0026amp;\u0026amp; format_print $pn $gn done done else for pn in $@;do is_process_in_config $pn \u0026amp;\u0026amp; format_print $pn $gn done fi else # 没有参数, 打印所有 for pn in `get_all_processes`;do gn=`get_group_by_process_name $pn` is_process_in_config $pn \u0026amp;\u0026amp; format_print $pn $gn done fi ","date":"2023-12-17T15:15:36+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/Shell脚本之进程管理/cover.jpg","permalink":"/p/shell%E8%84%9A%E6%9C%AC%E4%B9%8B%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","title":"Shell脚本之进程管理"},{"content":"mysql 命令参数 参数 含义 -u 用户 -p 密码 -h 要连接的主机 -D 指定数据库 -e 要执行的 sql 语句 -B 输出以 tab 分隔 -N 不显示列头 -E 垂直显示 -H 以 html 形式输出 -X xml 格式输出 shell 脚本接受 与, 操作 mysql\n1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash # user=\u0026#34;dbuser\u0026#34; password=\u0026#34;123456\u0026#34; host=\u0026#34;127.0.0.1\u0026#34; db_name=\u0026#34;$1\u0026#34; # 参数中用空格时要用双引号 SQL=\u0026#34;$2\u0026#34; mysql -u\u0026#34;$user\u0026#34; -p\u0026#34;$password\u0026#34; -h\u0026#34;$host\u0026#34; -D\u0026#34;db_name\u0026#34; -B -e \u0026#34;$SQL\u0026#34; 1 $ sh operator.sh school \u0026#34;insert into score(\u0026#34;231\u0026#34;,\u0026#34;1234\u0026#34;,100)\u0026#34; 使用 shell 导入数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #/bin/bash # user=\u0026#34;dbuser\u0026#34; password=\u0026#34;123456\u0026#34; host=\u0026#34;127.0.0.1\u0026#34; IFS=\u0026#34;|\u0026#34; # shell 默认以空格与 tab 切分, 通过 IFS 改变默认分隔符 cat data.txt | while read id name birth sex do if [ $id -gt 2023 ];then mysql -u\u0026#34;$user\u0026#34; -p\u0026#34;$password\u0026#34; -h\u0026#34;$host\u0026#34; -e \u0026#34;Insert into school.student values(\u0026#39;$id\u0026#39;,\u0026#39;$name\u0026#39;,\u0026#39;$birth\u0026#39;,\u0026#39;$sex\u0026#39;)\u0026#34; fi done 利用 mysqldump 进行数据库备份 mysqldump 参数 含义 -u -p -h -d \u0026ndash;no-data 只导出表结构 -t \u0026ndash;no-create-info 只导出数据, 不导出建表语句 -A \u0026ndash;all-databases \u0026ndash;all-databases -B \u0026ndash;databases 导出一个或多个数据库 备份 school 下的 score 表, 通过 ftp 上传到目标服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #!/bin/bash # db_user=\u0026#34;dbuser\u0026#34; db_password=\u0026#34;123456\u0026#34; db_host=\u0026#34;127.0.0.1\u0026#34; ftp_user=\u0026#34;fpt_user\u0026#34; ftp_password=\u0026#34;123\u0026#34; ftp_host=\u0026#34;127.0.0.1\u0026#34; src_dir=\u0026#34;/data/bak\u0026#34; dst_dir=\u0026#34;/data/backup\u0026#34; time=\u0026#34;`date +%Y%m%d%H%M%S`\u0026#34; filename=\u0026#34;school_score_${time}.bak\u0026#34; function auto_ftp { ftp -inv \u0026lt;\u0026lt; EOF open $ftp_host user $ftp_user $ftp_password cd $dst_dir put $1 bye EOF } # 备份 school 数据库下的 score 表 # \u0026amp;\u0026amp; 只有前一天命令正确执行在执行后面命令 mysqldump -u\u0026#34;$db_user\u0026#34; -p\u0026#34;$db_password\u0026#34; -h\u0026#34;db_host\u0026#34; school score \u0026gt; $src_dir/$filename \u0026amp;\u0026amp; auto_ftp $src_dir/$filename ","date":"2023-12-17T15:14:43+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/Shell脚本与Mysql交互/cover.png","permalink":"/p/shell%E8%84%9A%E6%9C%AC%E4%B8%8Emysql%E4%BA%A4%E4%BA%92/","title":"Shell脚本与Mysql交互"},{"content":"函数定义与使用 语法格式\nnginx 守护进程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #!/bin/bash # while true do ps -ef | grep nginx | grep -v grep | grep -v $$ \u0026amp;\u0026gt; /dev/null if [ $? -eq 0 ]; then echo \u0026#34;nginx is running\u0026#34; sleep 3s else echo \u0026#34;nginx is stop, starting\u0026#34; systemctl start nginx fi done 简单计算函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/bin/bash # function calcu { case $2 in +) echo `expr $1 + $3` ;; -) echo `expr $1 - $3` ;; \\*) echo `expr $1 \\* $3` ;; /) echo `expr $1 / $3` ;; esac } calcu $1 $2 $3 函数返回值 return echo return 返回值案例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/bin/bash # function is_nginx_isrunning { ps -ef | grep nginx | grep -v grep | grep $$ \u0026amp;\u0026gt; /dev/null if [ $? -eq 0 ]; then return else return 1 fi } is_nginx_running \u0026amp;\u0026amp; echo \u0026#34;nginx is running\u0026#34; || echo \u0026#34;nginx is not running\u0026#34; echo 返回值案例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bahs # function get_users { users=`cat /etc/passwd | cut -d \u0026#34;:\u0026#34; -f1` echo $users } userlist=`get_users` index=1 for u in ${userlist[@]} # 也可以 $userlist do echo \u0026#34;This is $index user: $u\u0026#34; index=$(($index+1)) done 全局变量与局部变量 Shell 中默认为全局变量\n局部变量使用 local 关键字\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/bin/bash # var1=1 function set_var2 { var2=2 } echo $var1 echo $var2 set_var2 echo $var2 function set_var3 { local var3=3 } set_var3 echo $var3 输出:\n1 2 3 1 2 函数库 库文件通常以 .lib 结尾\nbase_function.lib\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/echo # 提示不可运行 function add { echo \u0026#34;`expr $1 + $2`\u0026#34; } function divide { echo \u0026#34;`expr $1 / $2`\u0026#34; } function sys_load { echo \u0026#34;Memory Info\u0026#34; echo free -m echo echo \u0026#34;Disk Info\u0026#34; echo df -h echo } use_base_function.sh\n1 2 3 4 5 6 7 8 9 10 #!/bin/bash # . /root/shell/base_function.lib # 也可以用 source; 要用绝对路径 add 1 2 divide 7 3 sys_load ","date":"2023-12-17T15:14:06+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/Shell函数/cover.png","permalink":"/p/shell%E5%87%BD%E6%95%B0/","title":"Shell函数"},{"content":"常用选项 (找文件) 语法格式 选项参数表: 常用 解释 -name find /etc -name \u0026lsquo;*conf\u0026rsquo; -iname find /etc -name \u0026lsquo;*conf\u0026rsquo; 忽略大小写 -user find . -user username -group find . -group groupname -type find . -type f -size find /etc -size -10000c 查找小于10000字节的文件 -type 参数 -type 参数 对应文件类型 f 文件类型 d 目录 c 字符设备文件 b 块设备文件 l 链接文件 p 管道文件 -size 参数 -size 参数 说明 -n find /etc -size -10000c 查找小于10000字节的文件 +n find /etc -size +1M 查找大于10000字节的文件 c : 字节\nk: 1000字节\nM : Mb\n-mtime 以天为单位\n-mtime 参数 说明 -n n 天内修改的文件 +n n 天以前修改的文件 n 第 n 天修改的文件 示例\n查找 /etc 下 5 天内修改的文件, 并以 conf 结尾 查找 /etc 10 天前修改的文件, 属主为 root 1 2 3 $ find /etc -mtime -5 -name \u0026#39;*conf\u0026#39; $ find /etc -mtime +10 -user root -mmin -mmin 参数 说明 -n n 分钟内修改 +n n 分钟以前修改 -mindepth 要作为 find 第一个选项\n从第 n 级子目录开始搜索\n要搜索的目录为第一个目录\n-maxdepth -newer\n1 $ find /etc -newer 123.txt # 查找比 123.txt 更新的文件 find 操作 (执行) -print -exec -ok : 与 -exec 一致, 需要用户交互 -exec 删除\n1 $ find ./etc -name \u0026#34;*conf\u0026#34; -exec rm -rf {} \\; 复制\n1 $ find ./etc -size +1M -exec cp {} ./test/ \\; 练习: 把 /var/log/ 下 7 天以上的文件删除\n1 $ find /var/log/ -name \u0026#34;*.log\u0026#34; -mtime +7 -exec rm -rf {} \\; 逻辑运算符 -a 与 -o 或 -not | ! 非 1 2 3 4 5 6 7 $ find . -not -user \u0026lt;username\u0026gt; $ find . ! -user \u0026lt;username\u0026gt; $ find -type f -a -user \u0026lt;username\u0026gt; -a -size +300c # 属主为 ? 或以 .yml 结尾的文件 $ find . -type f -a \\( -user \u0026lt;username\u0026gt; -o -name \u0026#39;*.yml\u0026#39; \\) 其他查找命令 locate: 默认部分匹配 位于软件包 mlocate\nfind 是直接从磁盘中查找, locate 是从数据库中查找\n数据库文件位置: /var/lib/mlocate/mlocate.db -\u0026gt; 通过 updatedb 更新数据库文件\n数据库配置文件: /etc/updatedb.conf\n在后台 cron 定定时任务执行更新\nwhereis: 查找二进制文件 选项 说明 -b 二进制文件 -m 返回帮助文档 -s 返回源代码文件 which: 查找二进制程序文件 1 which mysql ","date":"2023-12-17T15:13:03+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/find文件查找/cover.png","permalink":"/p/find%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE/","title":"Find文件查找"},{"content":"1. 变量替换 语法 解释 ${变量#匹配规则} 从头开始匹配, 删除最短匹配 ${变量##匹配规则} 从头开始匹配, 删除最长匹配(贪婪匹配) ${变量%匹配规则} 从尾部开始匹配, 删除最短匹配 ${变量%%匹配规则} 从尾部开始匹配, 删除最长匹配(贪婪匹配) ${变量/旧字符串/新字符串} 替换变量, 只替换第一个匹配项 ${变量//旧字符串/新字符串} 替换变量, 替换所有匹配项 示例: 1 $ var=\u0026#34;I love you, Do you love me\u0026#34; ${变量#匹配规则}\n1 2 $ var1=${var#*ov} # 匹配时从第一个字符开始匹配 $ echo $var1 输出:\n1 e you, Do you love me ${变量##匹配规则}\n1 2 $ var2=${var##*ov} $ echo $var2 输出:\n1 e me ${变量%匹配规则}\n1 2 $ var3=${var%ov*} $ echo $var3 输出:\n1 I love you, Do you l ${变量%%匹配规则}\n1 2 $ var4=${var%%ov*} $ echo $var4 输出:\n1 I l ${变量/旧字符串/新字符串}\n1 $ echo $PATH 输出:\n1 /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin 1 2 $ var5=${PATH/bin/BIN} $ echo $var5 输出:\n1 /usr/local/sBIN:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin ${变量//旧字符串/新字符串}\n1 2 $ var6=${PATH//bin/BIN} $ echo $var6 输出:\n1 /usr/local/sBIN:/usr/local/BIN:/usr/sBIN:/usr/BIN:/sBIN:/BIN:/snap/BIN 2. 变量测试 变量测试实际用得较少, 大多都可以通过if-else替换\n变量替换参照表\n示例: var=${str-expr}\n1. 没有设置变量\n1 2 $ unset var $ echo ${var-expr} 输出:\n1 expr 2. 设置变量, 且变量为空\n1 2 $ var= $ echo ${var-expr} 输出:\n1 # 输出空值 3. 设置变量, 且变量非空\n1 2 $ var=test $ echo ${var-expr} 输出:\n1 test 3. 字符串处理 计算字符串长度 语法 说明 方法一 ${#string} 无 方法二 expr length \u0026ldquo;$string\u0026rdquo; string 有空格，则必须加双引号, (建议加上 \u0026quot;\u0026quot; ) 示范\n1 2 3 4 5 $ str=shellLearning $ echo ${#str} # 13 $ echo $(expr length \u0026#34;$str\u0026#34;) # 13 获取字符在字符串中的索引位置 1 2 3 4 5 6 7 8 9 $ expr index \u0026#34;$string\u0026#34; $substring $ var=\u0026#34;kubernetes is popular\u0026#34; $ idx=`expr index \u0026#34;$var\u0026#34; t` # var 中有空格, 加 \u0026#34;\u0026#34; $ echo $idx # 8 $ idx=`expr index \u0026#34;$var\u0026#34; te` # 子串会被拆成一个个字符一次匹配, 返回第一个匹配 $ echo $idx # 4 获取子串长度 1 2 3 4 5 6 7 8 9 $ expr match \u0026#34;$var\u0026#34; substr # 子串必须从头第一个字符开始匹配 $ var=\u0026#34;kubernetes is popular\u0026#34; $ idx=`expr match \u0026#34;$var\u0026#34; popu` $ echo $idx # 0 $ idx=`expr match \u0026#34;$var\u0026#34; ku.*` $ echo $idx # 21 抽取子串 语法 说明 ${string:position} 从 string 中 position 开始到结尾 ${string:position:length} 从 string 中 position 开始, 匹配长度为 length ${string: -position} 从右边开始匹配 ${string:(position)} 从左边开始匹配 expr substr \u0026ldquo;$string\u0026rdquo; $position $length 从 string 中 position 开始, 匹配长度为 length :索引从 0 开始\nexpr 索引从 1 开始\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ var=\u0026#34;kubecetes istio etcd operator\u0026#34; $ substr=${var:7} $ echo $substr # es istio etcd operator $ substr=${var:7:6} $ echo $substr # es ist $ substr=${var: -7} $ echo $substr # perator $ substr=${var:(-7)} $ echo $substr # perator $ substr=`expr substr \u0026#34;$var\u0026#34; 7 6` # tes is 脚本练习 思路:\n根据功能划分, 编写响应函数 实现定义函数 主流程设计 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 #!/bin/bash # str=\u0026#34;Bigdata process framework is Hadoop,Hadoop is an open source project\u0026#34; function print_tips { echo \u0026#34;************************************\u0026#34; echo \u0026#34;(1) 打印 string 长度\u0026#34; echo \u0026#34;(2) 删除字符串中所有的 Hadoop\u0026#34; echo \u0026#34;(3) 替换第一个 Hadoop 为 Mapreduce\u0026#34; echo \u0026#34;(4) 替换全部 Hadoop 为 Mapreduce\u0026#34; echo \u0026#34;************************************\u0026#34; } function len_of_string { echo \u0026#34;${#str}\u0026#34; } function del_hadoop { echo \u0026#34;${str//Hadoop/}\u0026#34; } function replace_hadoop_mapreduce_first { echo \u0026#34;${str/Hadoop/Mapreduce}\u0026#34; } function replace_hadoop_mapreduce_all { echo \u0026#34;${str//Hadoop/Mapreduce}\u0026#34; } while true do echo \u0026#34;[string: $str]\u0026#34; echo print_tips read -p \u0026#34;Please input your choice(1|2|3|4|q|Q): \u0026#34; choice case $choice in 1) len_of_string ;; 2) del_hadoop ;; 3) replace_hadoop_mapreduce_first ;; 4) replace_hadoop_mapreduce_all ;; q|Q) exit ;; *) echo \u0026#34;Error input, only {1|2|3|4|q|Q}\u0026#34; ;; esac done 4. 命令替换 使用 `command` 使用 $(command) 示例 获取系统所有用户\n1 2 3 4 5 6 7 8 9 #!/bin/bash # index=1 for user in `cat /etc/passwd | cut -d \u0026#34;:\u0026#34; -f 1` do echo \u0026#34;This is $index user: $user\u0026#34; index=$(($index+1)) # ((index++)) done 获取年份\n1 2 3 4 5 6 $ echo $(($(date +%Y) + 1)) # 2024 # 等价 $ echo $((num1+num2)) $ echo $(($num1+$num2)) 计算星期\n1 2 3 4 5 6 #!/bin/bash # echo \u0026#34;Today is the $(date +%j) of year.\u0026#34; echo \u0026#34;This year has passed $(($(date +%j) / 7)) weeks\u0026#34; echo \u0026#34;This year has $(((365-$(date +%j)) / 7))\u0026#34; 判断进程是否存活\n1 2 3 4 5 6 7 8 #!/bin/bash # nginx_num=$(ps -ef | grep nginx | grep -v grep | wc -l) if [ $nginx_num -eq 0 ]; then systemctl start nginx fi 有类型变量 declare 与 typeset 命令\n两者等价\ndeclare 命令参数表:\n与之相反, 取消变量, 把-改为+\n5. Bash 数学运算 expr 与 $(()) $(()) : 只可用于加减乘除\n参数表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ num1=17 $ num2=5 $ expr $num1 + $num2 # 22 $ expr $num1 - $num2 # 12 $ expr $num1 \\* $num2 # 85 $ expr $num1 / $num2 # 3 $ expr $num1 % $num2 # 2 $ expr $num1 \\\u0026gt; $num2 # 真为 1, 假为 0 # 1 $ expr $num1 \\\u0026lt; $num2 # 0 练习:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash # while true do read -p \u0026#34;Pls input a integer: \u0026#34;: num expr $num + 1 \u0026amp;\u0026gt; /dev/null # expr 只支持整数 if [ $? -eq 0 ]; then if [ `expr $num \\\u0026gt; 0` -eq 1 ]; then for((i=1;i\u0026lt;$num;i++)) do sum=`expr $sum + $i ` done echo \u0026#34;1+2+...+$num = $sum\u0026#34; exit else echo \u0026#34;error not positive\u0026#34; fi else echo \u0026#34;error inlegle input\u0026#34; fi done bc 只支持指数运算 1 2 3 4 $ echo \u0026#34;7.6/3.7\u0026#34; | bc # 2 $ echo \u0026#34;scale=4;7.6/3.7\u0026#34; | bc # bc 中 scale 为精度 # 2.0540 ","date":"2023-12-17T14:56:44+08:00","image":"https://blog-source-mkt.oss-cn-chengdu.aliyuncs.com/blog_source/post/images/Shell变量/cover.webp","permalink":"/p/shell%E5%8F%98%E9%87%8F/","title":"Shell变量"}]